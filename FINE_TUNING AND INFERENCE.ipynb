{"cells":[{"cell_type":"markdown","metadata":{"id":"Tj3fGQlPUEZP"},"source":["## Data Workflow for Data Extraction - CUADv1 - Fine Tune Transformer"]},{"cell_type":"code","source":["!pip install wandb --quiet\n","!pip install transformers --quiet\n","!pip install datasets --quiet\n","!pip install seqeval --quiet\n","!pip install sentencepiece --quiet\n","!pip install --upgrade accelerate --quiet"],"metadata":{"id":"ck7Z6inwUkJt","executionInfo":{"status":"ok","timestamp":1685526087430,"user_tz":-300,"elapsed":53922,"user":{"displayName":"Abid Hussain","userId":"09813020101850201886"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8b9f598c-0ea4-4ddd-f022-9ddadb396d94"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.5/206.5 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m118.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.1/219.1 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GdKdT3niUJW9","executionInfo":{"status":"ok","timestamp":1685525917354,"user_tz":-300,"elapsed":36095,"user":{"displayName":"Abid Hussain","userId":"09813020101850201886"}},"outputId":"29ccf017-7e9f-447c-f1de-cf34f37bdede"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"IJ6ER7jFUEZS"},"source":["#### Sources of information, code and discussions"]},{"cell_type":"markdown","metadata":{"id":"wTNSF4eaUEZS"},"source":["\n","1. The foundation workflow is from Hugging Face's Token Classification example hosted on Colab [here][1]\n","2. The models are base models, each using a downstream token clasification task, example [here][2]\n","\n","[1]: https://colab.research.google.com/github/huggingface/notebooks/blob/master/examples/token_classification.ipynb\n","[2]: https://huggingface.co/roberta-base"]},{"cell_type":"markdown","metadata":{"id":"L2rsIcVaUEZS"},"source":["# Initialize Environment"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"GSy6fxKHUEZT","executionInfo":{"status":"ok","timestamp":1685526757800,"user_tz":-300,"elapsed":8661,"user":{"displayName":"Abid Hussain","userId":"09813020101850201886"}}},"outputs":[],"source":["import os\n","os.chdir(\"/content/drive/MyDrive/CUAD_NER_TRANSFORMERS/\")\n","cwd = os.getcwd()\n","\n","import os, re, math, random, json, string\n","# Logging date for w&b\n","from datetime import date\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from IPython.display import display, HTML\n","import wandb\n","\n","import transformers\n","from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n","from transformers import TrainerCallback, AdamW, get_cosine_schedule_with_warmup\n","from transformers import DataCollatorForTokenClassification, PreTrainedModel, RobertaTokenizerFast\n","\n","from datasets import load_dataset, ClassLabel, Sequence, load_metric\n","\n","from seqeval.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gh8T4RdFUEZT","executionInfo":{"status":"ok","timestamp":1684779947284,"user_tz":-300,"elapsed":5717,"user":{"displayName":"Abid Hussain","userId":"09813020101850201886"}},"outputId":"64c4c816-901c-4e24-d8f0-ee1bda257696"},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mengr2243\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}],"source":["# Need to log in to weights and biases in the command line using: wandb login\n","wandb.login()"]},{"cell_type":"markdown","metadata":{"id":"snoo_LINUEZW"},"source":["### Step1: File and dataset handling\n","Data cleaning, annotations and  formatting has already been done, tokenized to seperate words, tagged using the IOB format and serialized using the Pandas df.to_json() function using the orient=\"table\" parameter to a JSONL file. \n","\n","Here we load in the dataset with this JSON format."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"MTUoXLEUUEZW","executionInfo":{"status":"error","timestamp":1685526731138,"user_tz":-300,"elapsed":633,"user":{"displayName":"Abid Hussain","userId":"09813020101850201886"}},"colab":{"base_uri":"https://localhost:8080/","height":165},"outputId":"1e675775-38e4-4646-e002-6eeeff96dfa5"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-93e2805c53d1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDATA_FILE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcwd\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m'/cuad-v1-annotated.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'cwd' is not defined"]}],"source":["DATA_FILE = cwd+ '/cuad-v1-annotated.json'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":86,"referenced_widgets":["9b63701a33ef426cb0bb9216f0cb7192","5c1da94929f64828ac11e46e0d012f85","0d11e3b721194fc59b79ff6bbf3d773c","dc72b321379f4e3a8dad9df0491b9ec1","aa75fea8697b452f8d6caef70fb679db","6aa55213e0ca4d799b4221013445a15f","3282431008dc4325b9c5dd0cbdcdb20b","47125015657748dcaf3cea1528263c37","3cd12af3fc5b42fea79376fee0368d51","aa7480123fcc43a58c252ef363038bdf","7ad542532b1d4ccfaf3096f5f4754fcd"]},"id":"Hn0d8yutUEZW","executionInfo":{"status":"ok","timestamp":1684779947284,"user_tz":-300,"elapsed":9,"user":{"displayName":"Abid Hussain","userId":"09813020101850201886"}},"outputId":"f19a5b6c-4f5b-4af1-f346-06115ca32f85"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:Found cached dataset json (/root/.cache/huggingface/datasets/json/default-702f038ab1acf893/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b63701a33ef426cb0bb9216f0cb7192"}},"metadata":{}}],"source":["data_files = DATA_FILE\n","datasets = load_dataset('json', data_files=data_files, field='data')"]},{"cell_type":"markdown","metadata":{"id":"lEh8PMOhUEZY"},"source":["```\n","# This is formatted as code\n","```\n","\n","### **Step 3: Buiding, Training and Validating model**\n","Since all our tasks are about token classification, we use the AutoModelForTokenClassification class. Like with the tokenizer, the from_pretrained method will download and cache the model for us. The only thing we have to specify is the number of labels for our problem (which we can get from the features, as seen before).\n","\n","The warning is telling us we are throwing away some weights (the vocab_transform and vocab_layer_norm layers) and randomly initializing some other (the pre_classifier and classifier layers). This is absolutely normal in this case, because we are removing the head used to pretrain the model on a masked language modeling objective and replacing it with a new head for which we don't have pretrained weights, so the library warns us we should fine-tune this model before using it for inference, which is exactly what we are going to do."]},{"cell_type":"markdown","metadata":{"id":"oQxe2tgpUEZZ"},"source":["#### Training Schedule\n","This is a common train schedule for transfer learning. The learning rate starts at zero, to initially preserve the pre-trained weights, then increases to a maximum, then reduces using a cosine exponential curve to attempt to find the global optima.\n","\n","Changing the schedule and/or learning rates is a popular way to experiment to find good model performance. Note how the learning rate max is larger with larger batches sizes. This is a good practice to follow.\n","\n","Weight decay is the amount of L2 regularization to force into the model's optimizer to make it work harder and offset any tendancy for the model to overfit."]},{"cell_type":"markdown","metadata":{"id":"3fK_XkKMUEZZ"},"source":["\n","To instantiate a Trainer, we will need to define three more things. The most important is the TrainingArguments, which is a class that contains all the attributes to customize the training. It requires one folder name, which will be used to save the checkpoints of the model, and all other arguments are optional."]},{"cell_type":"markdown","metadata":{"id":"pE60Vdv-UEZa"},"source":["Then we will need a data collator that will batch our processed examples together while applying padding to make them all the same size (each pad will be padded to the length of its longest example). There is a data collator for this task in the Transformers library, that not only pads the inputs, but also the labels."]},{"cell_type":"markdown","metadata":{"id":"r06Y_VEwUEZa"},"source":["The last thing to define for our Trainer is how to compute the metrics from the predictions. Here we will load the seqeval metrics (which are commonly used to evaluate results on the benchmark CONLL dataset). https://github.com/chakki-works/seqeval\n","\n","Note - Either BILOU or IOB tags can be used. Whilst BILOU provides for more features, research suggests using the simpler IOB for token classification shouldn't impact accuracy. \n","\n","So we will need to do a bit of post-processing on our predictions:\n"," - select the predicted index (with the maximum logit) for each token\n"," - convert it to its string label\n"," - ignore everywhere we set a label of -100\n","\n","The following function does all this post-processing on the result of Trainer.evaluate (which is a namedtuple containing predictions and labels) before applying the metric:"]},{"cell_type":"code","source":["# SPECIFY THE WEIGHTS AND BIASES PROJECT NAME\n","%env WANDB_PROJECT = 'P2D-NER-2021' \n","# DETERMINE WHETHER TO SAVE THE MODEL IN THE 100GB OF FREE W&B STORAGE\n","%env WANDB_LOG_MODEL = false \n","\n","class BUILD_MODEL:\n","  def __init__(self, DATASETS, MODEL_NAME,\n","               TRAIN_SPLIT, RANDOM_SEED,\n","               BATCH_SIZES, EPOCHS,\n","               FEATURE_CLASS_LABELS,\n","               TEMP_MODEL_OUTPUT_DIR,\n","               TRAIN, LR=0.0000075):\n","    \n","    #List of labels saved in the data preparation stage\n","    self.label_list = self.load_labels_list(FEATURE_CLASS_LABELS)\n","\n","    #Models to test: Update as required\n","    self.models = dict(\n","        ROBERTA = \"roberta-base\",\n","        DISTILBERT_U = \"distilbert-base-uncased\",\n","        DISTILBERT_C = \"distilbert-base-cased\",\n","        DEBERTA_V2_XL = \"microsoft/deberta-v2-xlarge\",\n","        DEBERTA_V2_XXL = \"microsoft/deberta-v2-xxlarge\")\n","    \n","    #Input Dataset\n","    self.DATASETS=DATASETS\n","\n","    #Name of model: Select based on models dictionary keys\n","    self.MODEL_NAME = MODEL_NAME\n","    \n","    # LOAD OR TRAIN MODEL: 1 to TRAIN WEIGHTS or 0 to LOAD WEIGHTS\n","    self.TRAIN = TRAIN \n","    \n","    # TRAIN/VALIDATION SPLIT\n","    self.TRAIN_SPLIT = TRAIN_SPLIT\n","\n","    # RANDOM SEED FOR REPRODUCIBILITY\n","    self.RANDOM_SEED = RANDOM_SEED\n","\n","    # BATCH SIZE\n","    # TRY 4, 8, 16, 32, 64, 128, 256. REDUCE IF OOM ERROR, HIGHER FOR TPUS\n","    self.BATCH_SIZES = BATCH_SIZES\n","\n","    # EPOCHS - TRANSFORMERS ARE TYPICALLY FINE-TUNED BETWEEN 1 AND 3 EPOCHS \n","    self.EPOCHS = EPOCHS\n","    \n","    #Path to Feature class labels saved\n","    self.FEATURE_CLASS_LABELS = FEATURE_CLASS_LABELS\n","    \n","    # Model out path\n","    self.TEMP_MODEL_OUTPUT_DIR = TEMP_MODEL_OUTPUT_DIR\n","\n","    #Learning Rate\n","    self.LR = LR\n","\n","  #Loads the list of labels\n","  def load_labels_list(self, FEATURE_CLASS_LABELS):\n","      # Open the label list created in pre-processing corresponding to the ner_tag indices\n","      with open(FEATURE_CLASS_LABELS, 'r') as f:\n","          label_list = json.load(f)\n","      return label_list\n","\n","#==================DATA PREPROCESSING AND TOKENIZATION=========================#\n","  def word_id_func(self, input_ids, tokenizer, print_labs=False):\n","      tokens = tokenizer.convert_ids_to_tokens(input_ids)\n","      \n","      word_ids = []\n","      i=0\n","      spec_toks = ['[CLS]', '[SEP]', '[PAD]']\n","      for t in tokens:\n","          if t in spec_toks:\n","              word_ids.append(-100)\n","              print(t, i) if print_labs else None\n","          elif t.startswith('▁'):\n","              i += 1\n","              word_ids.append(i)\n","              print(t, i) if print_labs else None\n","          else:\n","              word_ids.append(i)\n","              print(t, i) if print_labs else None\n","          print(\"Total:\", i) if print_labs else None\n","      return word_ids\n","\n","  def tokenize_and_align_labels(self, examples, tokenizer,  label_all_tokens=False):\n","      tokenized_inputs = tokenizer(examples[\"split_tokens\"],\n","                                  truncation=True,\n","                                  is_split_into_words=True)\n","      labels = []\n","      for i, label in enumerate(examples[\"ner_tags\"]):\n","          word_ids = tokenized_inputs.word_ids(batch_index=i)\n","          previous_word_idx = None\n","          label_ids = []\n","          for word_idx in word_ids:\n","              # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n","              # ignored in the loss function.\n","              if word_idx is None:\n","                  label_ids.append(-100)\n","              # We set the label for the first token of each word.\n","              elif word_idx != previous_word_idx:\n","                  label_ids.append(label[word_idx])\n","              # For the other tokens in a word, we set the label to either the current label or -100, depending on\n","              # the label_all_tokens flag.\n","              else:\n","                  label_ids.append(label[word_idx] if label_all_tokens else -100)\n","              previous_word_idx = word_idx\n","          labels.append(label_ids)\n","\n","      tokenized_inputs[\"labels\"] = labels\n","      return tokenized_inputs\n","\n","  def tokenize_and_align_labels_deberta(self, examples, tokenizer, label_all_tokens=False):\n","      tokenized_inputs = tokenizer(examples[\"split_tokens\"],\n","                                  truncation=True,\n","                                  is_split_into_words=True)\n","      labels = []\n","      word_ids_list = []\n","      for input_ids in tokenized_inputs[\"input_ids\"]:\n","          wids = self.word_id_func(input_ids, tokenizer,  print_labs=False)\n","          word_ids_list.append(wids)\n","      \n","      for i, label in enumerate(examples[\"ner_tags\"]):\n","          word_ids = word_ids_list[i]\n","          previous_word_idx = None\n","          label_ids = []\n","          for word_idx in word_ids:\n","              # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n","              # ignored in the loss function.\n","              if word_idx == -100:\n","                  label_ids.append(-100)\n","              #We set the label for the first token of each word.\n","              elif word_idx != previous_word_idx:\n","                  label_ids.append(label[word_idx-1])\n","              # For the other tokens in a word, we set the label to either the current label or -100, depending on\n","              # the label_all_tokens flag.\n","              else:\n","                  label_ids.append(label[word_idx-1] if label_all_tokens else -100)\n","              previous_word_idx = word_idx\n","          labels.append(label_ids)\n","\n","      tokenized_inputs[\"labels\"] = labels\n","      return tokenized_inputs\n","\n","\n","\n","  def SET_PARAMETERS(self, DATASETS, MODEL, MODEL_CHECKPOINT):\n","    EPOCHS = self.EPOCHS\n","    BATCH_SIZES = self.BATCH_SIZES\n","    RANDOM_SEED = self.RANDOM_SEED\n","\n","    today = date.today()\n","    log_date = today.strftime(\"%d-%m-%Y\")\n","\n","    #Optimizer\n","    learning_rate = self.LR\n","    lr_max = learning_rate * self.BATCH_SIZES\n","    weight_decay = 0.05\n","\n","    optimizer = AdamW(\n","        MODEL.parameters(),\n","        lr=lr_max,\n","        weight_decay=weight_decay)\n","\n","    print(\"The maximum learning rate is: \",lr_max)\n","\n","    # Learning Rate Schedule\n","    num_train_samples = len(DATASETS[\"train\"])\n","    warmup_ratio = 0.2 # Percentage of total steps to go from zero to max learning rate\n","    num_cycles=0.8 # The cosine exponential rate\n","\n","    num_training_steps = num_train_samples*EPOCHS/BATCH_SIZES\n","    num_warmup_steps = num_training_steps*warmup_ratio\n","\n","    lr_sched = get_cosine_schedule_with_warmup(optimizer=optimizer,\n","                                              num_warmup_steps=num_warmup_steps,\n","                                              num_training_steps = num_training_steps,\n","                                              num_cycles=num_cycles)\n","    \n","    args = TrainingArguments(output_dir = self.TEMP_MODEL_OUTPUT_DIR,\n","                        evaluation_strategy = \"epoch\",\n","                        learning_rate=lr_max,\n","                        per_device_train_batch_size=BATCH_SIZES,\n","                        per_device_eval_batch_size=BATCH_SIZES,\n","                        num_train_epochs=EPOCHS,\n","                        weight_decay=weight_decay,\n","                        lr_scheduler_type = 'cosine',\n","                        warmup_ratio=warmup_ratio,\n","                        logging_strategy=\"epoch\",\n","                        save_strategy=\"epoch\",\n","                        seed=RANDOM_SEED,\n","                        report_to = 'wandb', # enable logging to W&B\n","                        run_name = MODEL_CHECKPOINT+\"-\"+log_date,\n","                        metric_for_best_model=\"f1\",\n","                        load_best_model_at_end = True)   # name of the W&B run (optional)\n","      \n","    return args, lr_sched, optimizer\n","\n","#==================TRAINING AND EVALUATION======================================#\n","  def compute_metrics(self, p):\n","      label_list = self.label_list\n","      predictions, labels = p\n","      predictions = np.argmax(predictions, axis=2)\n","\n","      # Remove ignored index (special tokens)\n","      true_predictions = [\n","          [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n","          for prediction, label in zip(predictions, labels)]\n","      true_labels = [\n","          [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n","          for prediction, label in zip(predictions, labels)]\n","      \n","      # Define the metric parameters\n","      overall_precision = precision_score(true_labels, true_predictions, zero_division=1)\n","      overall_recall = recall_score(true_labels, true_predictions, zero_division=1)\n","      overall_f1 = f1_score(true_labels, true_predictions, zero_division=1)\n","      overall_accuracy = accuracy_score(true_labels, true_predictions)\n","      \n","      # Return a dictionary with the calculated metrics\n","      return {\n","          \"precision\": overall_precision,\n","          \"recall\": overall_recall,\n","          \"f1\": overall_f1,\n","          \"accuracy\": overall_accuracy,}\n","\n","  def TRAINING(self):\n","      # WHICH PRE-TRAINED TRANSFORMER TO FINE-TUNE?\n","      models = self.models\n","      MODEL_CHECKPOINT = models[self.MODEL_NAME]\n","      datasets = self.DATASETS\n","\n","      label_list = self.label_list\n","\n","      # Create train and validation datasets\n","      datasets = datasets['train'].train_test_split(test_size=1-TRAIN_SPLIT, seed=RANDOM_SEED)\n","\n","      # Instantiate the tokenizer\n","      #For RoBERTa-base, need to use RobertaTokenizerFast with add_prefix_space=True to use it with pretokenized inputs.\n","      # SentencePiece will need to be installed for DeBERTa v2: pip install sentencepiece\n","      if MODEL_CHECKPOINT == models['ROBERTA']:\n","          tokenizer = RobertaTokenizerFast.from_pretrained(MODEL_CHECKPOINT, add_prefix_space=True)\n","      else:\n","          tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n","\n","      # To apply this function on all the words and labels in our dataset,\n","      # we just use the map method of our dataset object we created earlier.\n","      # This will apply the function on all the elements of all the splits in dataset, so our training, \n","      # validation and testing data will be preprocessed in one single command.\n","\n","      # 🤗 Datasets warns you when it uses cached files, you can pass load_from_cache_file=False in the\n","      # call to map to not use the cached files and force the preprocessing to be applied again.\n","      tokenize_and_align_labels = self.tokenize_and_align_labels\n","      if MODEL_CHECKPOINT == models['DEBERTA_V2_XL'] or MODEL_CHECKPOINT == models['DEBERTA_V2_XXL']:\n","          tokenize_and_align_labels = self.tokenize_and_align_labels_deberta\n","\n","\n","      tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True,\n","                                        load_from_cache_file=True,\n","                                        fn_kwargs={\"tokenizer\": tokenizer})\n","      \n","      data_collator = DataCollatorForTokenClassification(tokenizer)\n","\n","      model = AutoModelForTokenClassification.from_pretrained(MODEL_CHECKPOINT, num_labels=len(label_list))\n","\n","      args, lr_sched, optimizer = self.SET_PARAMETERS(DATASETS=datasets, MODEL=model, MODEL_CHECKPOINT = MODEL_CHECKPOINT)\n","\n","      # Define and instantiate the Trainer...\n","      trainer = Trainer(\n","                model=model,\n","                args=args,\n","                train_dataset=tokenized_datasets[\"train\"],\n","                eval_dataset=tokenized_datasets[\"test\"],\n","                data_collator=data_collator,\n","                tokenizer=tokenizer,\n","                compute_metrics=self.compute_metrics,\n","                optimizers=(optimizer, lr_sched)\n","                )\n","      \n","      print('STARTING TRAINING----')\n","      trainer.train()\n","      print('TRAINING COMPLETED')\n","\n","      print('STARTING EVALUATION ON CHOSEN EPOCH---')\n","      # Evaluate based on the chosen epoch (usually best or last)\n","      trainer.evaluate()\n","      print('EVALUATION FINISHED---')\n","\n","      # Finish Weighs & Biases logging for this run\n","      wandb.finish()\n","\n","      # Save the model, good practice given the work required to train a model and  \n","      # also can be used just for inference on new data\n","      print(\"Saving model...\")\n","      SAVED_MODEL = cwd + f\"/models/p2d-NER-Fine-Tune-Transformer-{MODEL_CHECKPOINT}\" # Change for notebook version\n","      trainer.save_model(SAVED_MODEL)\n","      print(\"Saved_model model...\")\n","      return \n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b0OG40AOYvX9","executionInfo":{"status":"ok","timestamp":1684779881985,"user_tz":-300,"elapsed":12,"user":{"displayName":"Abid Hussain","userId":"09813020101850201886"}},"outputId":"f900bf03-bf42-42da-90e6-18e8f735162e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["env: WANDB_PROJECT='P2D-NER-2021'\n","env: WANDB_LOG_MODEL=false\n"]}]},{"cell_type":"markdown","source":["## TEST-1"],"metadata":{"id":"DcAOyg6ypD_O"}},{"cell_type":"code","source":["DATASETS = datasets\n","MODEL_NAME = \"ROBERTA\" #CHOOSE FROM ROBERTA = \"roberta-base\",DISTILBERT_U, DISTILBERT_C, DEBERTA_V2_XL, DEBERTA_V2_XXL      \n","TRAIN_SPLIT = 0.90\n","RANDOM_SEED = 42\n","BATCH_SIZES=1\n","EPOCHS = 10\n","FEATURE_CLASS_LABELS = cwd+\"/feature_class_labels.json\"\n","TEMP_MODEL_OUTPUT_DIR = cwd+'temp_model_output_dir'\n","TRAIN = 1\n","LR=0.0000075\n","\n","\n","BUILD_MODEL(DATASETS=DATASETS,\n","            MODEL_NAME=MODEL_NAME,\n","            TRAIN_SPLIT=TRAIN_SPLIT,\n","            RANDOM_SEED=RANDOM_SEED,\n","            BATCH_SIZES=BATCH_SIZES,\n","            EPOCHS=EPOCHS,\n","            FEATURE_CLASS_LABELS = FEATURE_CLASS_LABELS,\n","            TEMP_MODEL_OUTPUT_DIR=TEMP_MODEL_OUTPUT_DIR,\n","            TRAIN=TRAIN,\n","            LR=LR).TRAINING()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["43b9d17d3cbc49f98d54da8ac44f23bf","fce12e21d83649e8b850f87ba77d7bd2","1afb83a3c5be4887b86060692e125553","dcc9c5c391e846b7946b3fa359d871c0","ad5261a8925b4afeaaa092af1fec2d20","fcf0571d52b54ad681c2a44578831170","8ed272c98d1b4ecbb662c78a11c09631","3c8f8d053f4f4729b550ed87318c8f14","4e858979e07541a1b2ccb99e3c3de4e3","d5a5950d57b848ae911670f4d05039aa","38e9041d08ee4de794c1e7e3047e2607","f31ee30cc021427481069f69774fa957","95dc445d782c41f5b397830c3bec78c5","64569abcc17c4a44b3a116868f36f227","0d5446d926cb4ab8b577d6a4ca1c2690","66c8a05e6a1d4bdea692d0127621064e","8bc3eee1ec394b54bfd9b9bb673808a4","5b87173cfda14999986cc7c80fd224bd","ad3dbc86fbe94526a6ee0acbd05eb8d2","1dee7617de5c47f8ac7a22d71815d493","652de661cdc94d179d59ff713ffde6cf","510f4f03f609444b83cf1b103a77b8f2","45b622e410b94cbb81edbb9b0d3d0011","b682ddee653b4d7282531a431a83bddd","eee709fc357d4d8ab6087d45b4555567","47ba3478c8c0440498920debd931154a","5e17f1db76d24534b89e98dfbbd7edff","6129ea2bc3b447989aaee16a56fc7420","3d4f0e33499a4cbb9e4e54e130c9ba68","ee5fecdb0c6842229dae6dd563ce763b"]},"id":"cNTfeXNfK9-o","executionInfo":{"status":"ok","timestamp":1684778390585,"user_tz":-300,"elapsed":353442,"user":{"displayName":"Abid Hussain","userId":"09813020101850201886"}},"outputId":"de72b075-f154-42bf-d16b-0de82a7edaad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.arrow_dataset:Loading cached split indices for dataset at /root/.cache/huggingface/datasets/json/default-702f038ab1acf893/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-ad7f61e4e51f8372.arrow and /root/.cache/huggingface/datasets/json/default-702f038ab1acf893/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-2b4d212ce9922787.arrow\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/282 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43b9d17d3cbc49f98d54da8ac44f23bf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/32 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f31ee30cc021427481069f69774fa957"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForTokenClassification: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.bias']\n","- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["The maximum learning rate is:  7.5e-06\n","STARTING TRAINING----\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.3"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/CUAD_NER_TRANSFORMERS/wandb/run-20230522_175403-8mpnwio6</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/engr2243/%27P2D-NER-2021%27/runs/8mpnwio6' target=\"_blank\">roberta-base-22-05-2023</a></strong> to <a href='https://wandb.ai/engr2243/%27P2D-NER-2021%27' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/engr2243/%27P2D-NER-2021%27' target=\"_blank\">https://wandb.ai/engr2243/%27P2D-NER-2021%27</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/engr2243/%27P2D-NER-2021%27/runs/8mpnwio6' target=\"_blank\">https://wandb.ai/engr2243/%27P2D-NER-2021%27/runs/8mpnwio6</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2820' max='2820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2820/2820 05:36, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.651000</td>\n","      <td>0.130176</td>\n","      <td>0.641791</td>\n","      <td>0.697297</td>\n","      <td>0.668394</td>\n","      <td>0.959348</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.092500</td>\n","      <td>0.058230</td>\n","      <td>0.806452</td>\n","      <td>0.945946</td>\n","      <td>0.870647</td>\n","      <td>0.984514</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.051200</td>\n","      <td>0.043918</td>\n","      <td>0.863636</td>\n","      <td>0.924324</td>\n","      <td>0.892950</td>\n","      <td>0.987256</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.037000</td>\n","      <td>0.050029</td>\n","      <td>0.872549</td>\n","      <td>0.962162</td>\n","      <td>0.915167</td>\n","      <td>0.986772</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.027800</td>\n","      <td>0.049311</td>\n","      <td>0.870000</td>\n","      <td>0.940541</td>\n","      <td>0.903896</td>\n","      <td>0.987579</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.021000</td>\n","      <td>0.043977</td>\n","      <td>0.893401</td>\n","      <td>0.951351</td>\n","      <td>0.921466</td>\n","      <td>0.989998</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.019300</td>\n","      <td>0.048092</td>\n","      <td>0.898477</td>\n","      <td>0.956757</td>\n","      <td>0.926702</td>\n","      <td>0.989192</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.018600</td>\n","      <td>0.050502</td>\n","      <td>0.885000</td>\n","      <td>0.956757</td>\n","      <td>0.919481</td>\n","      <td>0.988385</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.019100</td>\n","      <td>0.052557</td>\n","      <td>0.871921</td>\n","      <td>0.956757</td>\n","      <td>0.912371</td>\n","      <td>0.988547</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.018500</td>\n","      <td>0.064970</td>\n","      <td>0.841584</td>\n","      <td>0.918919</td>\n","      <td>0.878553</td>\n","      <td>0.986933</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["TRAINING COMPLETED\n","STARTING EVALUATION ON CHOSEN EPOCH---\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [32/32 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["EVALUATION FINISHED---\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45b622e410b94cbb81edbb9b0d3d0011"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▇▇▇▇████▇█</td></tr><tr><td>eval/f1</td><td>▁▆▇█▇████▇█</td></tr><tr><td>eval/loss</td><td>█▂▁▁▁▁▁▂▂▃▁</td></tr><tr><td>eval/precision</td><td>▁▅▇▇▇███▇▆█</td></tr><tr><td>eval/recall</td><td>▁█▇█▇████▇█</td></tr><tr><td>eval/runtime</td><td>▄▂▂▁▃▁▄▁▃▁█</td></tr><tr><td>eval/samples_per_second</td><td>▅▇▇█▆█▅█▆█▁</td></tr><tr><td>eval/steps_per_second</td><td>▅▇▇█▆█▅█▆█▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/learning_rate</td><td>▅█▇▆▃▂▁▂▃▆</td></tr><tr><td>train/loss</td><td>█▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.98919</td></tr><tr><td>eval/f1</td><td>0.9267</td></tr><tr><td>eval/loss</td><td>0.04809</td></tr><tr><td>eval/precision</td><td>0.89848</td></tr><tr><td>eval/recall</td><td>0.95676</td></tr><tr><td>eval/runtime</td><td>0.7158</td></tr><tr><td>eval/samples_per_second</td><td>44.707</td></tr><tr><td>eval/steps_per_second</td><td>44.707</td></tr><tr><td>train/epoch</td><td>10.0</td></tr><tr><td>train/global_step</td><td>2820</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0185</td></tr><tr><td>train/total_flos</td><td>361253992373340.0</td></tr><tr><td>train/train_loss</td><td>0.0956</td></tr><tr><td>train/train_runtime</td><td>340.0865</td></tr><tr><td>train/train_samples_per_second</td><td>8.292</td></tr><tr><td>train/train_steps_per_second</td><td>8.292</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">roberta-base-22-05-2023</strong> at: <a href='https://wandb.ai/engr2243/%27P2D-NER-2021%27/runs/8mpnwio6' target=\"_blank\">https://wandb.ai/engr2243/%27P2D-NER-2021%27/runs/8mpnwio6</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230522_175403-8mpnwio6/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving model...\n","Saved_model model...\n"]}]},{"cell_type":"markdown","source":["## TEST-2"],"metadata":{"id":"3NOEh5j1pMZi"}},{"cell_type":"code","source":["DATASETS = datasets\n","MODEL_NAME = \"DISTILBERT_U\" #CHOOSE FROM ROBERTA = \"roberta-base\",DISTILBERT_U, DISTILBERT_C, DEBERTA_V2_XL, DEBERTA_V2_XXL      \n","TRAIN_SPLIT = 0.90\n","RANDOM_SEED = 42\n","BATCH_SIZES=1\n","EPOCHS = 10\n","FEATURE_CLASS_LABELS = cwd+\"/feature_class_labels.json\"\n","TEMP_MODEL_OUTPUT_DIR = cwd+'temp_model_output_dir'\n","TRAIN = 1\n","LR=0.0000075\n","\n","\n","BUILD_MODEL(DATASETS=DATASETS,\n","            MODEL_NAME=MODEL_NAME,\n","            TRAIN_SPLIT=TRAIN_SPLIT,\n","            RANDOM_SEED=RANDOM_SEED,\n","            BATCH_SIZES=BATCH_SIZES,\n","            EPOCHS=EPOCHS,\n","            FEATURE_CLASS_LABELS = FEATURE_CLASS_LABELS,\n","            TEMP_MODEL_OUTPUT_DIR=TEMP_MODEL_OUTPUT_DIR,\n","            TRAIN=TRAIN,\n","            LR=LR).TRAINING()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["524cf5389f0e4389bb98a0eb5fcd402b","ab4bed901b834ec893673faa45a4fced","371bad6779cc4182a432512fa8fc2352","63aa42397a6c496eb1eb3089fd3c96de","45ef8569369f41e0a0f2b54560b299f8","5078c296a59443e2b12f08aeb122645c","e212308a0a27479f9b9cd7727a59837e","81fa2bad7c26428f96f3593ba6259459","5ca2f05d6821428a8362bddc99778e9d","4933be1250784e1e865e92fe917670cd","14d8f31d7ecb470d8fcf1cbb53e66470","b654246a4e28452d8e3265b13812ca51","7e3cee45b58446e28854156c400dd0ae","992420820c714368bf2d3b54edfb9e7e","2a508ae050cd4f68a10962a0c5a061a7","73abe7dd90f54d349423c24b07d48644","74c88a9876294f8cbdac4dfa42058c5e","67b5fe76480141ab9d728cbd7509ce2d","5ef3d85520534f8b955f4505021fb090","9ecbabeeb4af46869c0246d409cf0f5c","961a955d107744a3897bf1074d89088c","a0ca00e01e964befb7f0cdfd490f86a6","c5c74f68f08c4381b4898b9d9af1cc75","0202f7938b934c70a9eca787efa24b95","888c57b882cf4ab7ae9c1ef758f6613b","be01eea9866240aaac4e5dc06d785683","88204526bf504876a30d5eefc76b93aa","6356fcf32fe14e2a8abc69562738958d","c014ffe390d8456dbce26372e7d3c8ea","1d61df64ed324eafb3139f76cb964ef0"]},"id":"qLzUVJ31pPAO","executionInfo":{"status":"ok","timestamp":1684778576900,"user_tz":-300,"elapsed":186343,"user":{"displayName":"Abid Hussain","userId":"09813020101850201886"}},"outputId":"281c69d4-8556-49d9-ccbf-364cdfed97f8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.arrow_dataset:Loading cached split indices for dataset at /root/.cache/huggingface/datasets/json/default-702f038ab1acf893/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-ad7f61e4e51f8372.arrow and /root/.cache/huggingface/datasets/json/default-702f038ab1acf893/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-2b4d212ce9922787.arrow\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/282 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"524cf5389f0e4389bb98a0eb5fcd402b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/32 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b654246a4e28452d8e3265b13812ca51"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForTokenClassification: ['vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["The maximum learning rate is:  7.5e-06\n","STARTING TRAINING----\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.3"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/CUAD_NER_TRANSFORMERS/wandb/run-20230522_175954-yj9izqao</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/engr2243/%27P2D-NER-2021%27/runs/yj9izqao' target=\"_blank\">distilbert-base-uncased-22-05-2023</a></strong> to <a href='https://wandb.ai/engr2243/%27P2D-NER-2021%27' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/engr2243/%27P2D-NER-2021%27' target=\"_blank\">https://wandb.ai/engr2243/%27P2D-NER-2021%27</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/engr2243/%27P2D-NER-2021%27/runs/yj9izqao' target=\"_blank\">https://wandb.ai/engr2243/%27P2D-NER-2021%27/runs/yj9izqao</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2820' max='2820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2820/2820 02:52, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.070100</td>\n","      <td>0.278909</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.902565</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.144300</td>\n","      <td>0.078494</td>\n","      <td>0.810526</td>\n","      <td>0.832432</td>\n","      <td>0.821333</td>\n","      <td>0.981449</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.066900</td>\n","      <td>0.052848</td>\n","      <td>0.840206</td>\n","      <td>0.881081</td>\n","      <td>0.860158</td>\n","      <td>0.985965</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.046400</td>\n","      <td>0.053920</td>\n","      <td>0.865285</td>\n","      <td>0.902703</td>\n","      <td>0.883598</td>\n","      <td>0.985643</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.034100</td>\n","      <td>0.049228</td>\n","      <td>0.870466</td>\n","      <td>0.908108</td>\n","      <td>0.888889</td>\n","      <td>0.986127</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.028800</td>\n","      <td>0.050217</td>\n","      <td>0.878307</td>\n","      <td>0.897297</td>\n","      <td>0.887701</td>\n","      <td>0.986449</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.025300</td>\n","      <td>0.050736</td>\n","      <td>0.883598</td>\n","      <td>0.902703</td>\n","      <td>0.893048</td>\n","      <td>0.986933</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.025500</td>\n","      <td>0.051075</td>\n","      <td>0.879581</td>\n","      <td>0.908108</td>\n","      <td>0.893617</td>\n","      <td>0.986449</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.025700</td>\n","      <td>0.050423</td>\n","      <td>0.865979</td>\n","      <td>0.908108</td>\n","      <td>0.886544</td>\n","      <td>0.986772</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.023700</td>\n","      <td>0.055131</td>\n","      <td>0.859296</td>\n","      <td>0.924324</td>\n","      <td>0.890625</td>\n","      <td>0.986933</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["TRAINING COMPLETED\n","STARTING EVALUATION ON CHOSEN EPOCH---\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [32/32 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["EVALUATION FINISHED---\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5c74f68f08c4381b4898b9d9af1cc75"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁██████████</td></tr><tr><td>eval/f1</td><td>▁▇█████████</td></tr><tr><td>eval/loss</td><td>█▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/precision</td><td>▁▇█████████</td></tr><tr><td>eval/recall</td><td>▁▇█████████</td></tr><tr><td>eval/runtime</td><td>▂▄▁▂▅▂█▁▁▁▇</td></tr><tr><td>eval/samples_per_second</td><td>▆▅█▇▄▇▁█▇█▂</td></tr><tr><td>eval/steps_per_second</td><td>▆▅█▇▄▇▁█▇█▂</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/learning_rate</td><td>▅█▇▆▃▂▁▂▃▆</td></tr><tr><td>train/loss</td><td>█▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.98645</td></tr><tr><td>eval/f1</td><td>0.89362</td></tr><tr><td>eval/loss</td><td>0.05108</td></tr><tr><td>eval/precision</td><td>0.87958</td></tr><tr><td>eval/recall</td><td>0.90811</td></tr><tr><td>eval/runtime</td><td>0.4221</td></tr><tr><td>eval/samples_per_second</td><td>75.812</td></tr><tr><td>eval/steps_per_second</td><td>75.812</td></tr><tr><td>train/epoch</td><td>10.0</td></tr><tr><td>train/global_step</td><td>2820</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0237</td></tr><tr><td>train/total_flos</td><td>161720796883140.0</td></tr><tr><td>train/train_loss</td><td>0.14908</td></tr><tr><td>train/train_runtime</td><td>175.6847</td></tr><tr><td>train/train_samples_per_second</td><td>16.051</td></tr><tr><td>train/train_steps_per_second</td><td>16.051</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">distilbert-base-uncased-22-05-2023</strong> at: <a href='https://wandb.ai/engr2243/%27P2D-NER-2021%27/runs/yj9izqao' target=\"_blank\">https://wandb.ai/engr2243/%27P2D-NER-2021%27/runs/yj9izqao</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230522_175954-yj9izqao/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving model...\n","Saved_model model...\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"xP9IpDs-pJbq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## TEST-3"],"metadata":{"id":"asIbthmspLTN"}},{"cell_type":"code","source":["DATASETS = datasets\n","MODEL_NAME = \"DISTILBERT_C\" #CHOOSE FROM ROBERTA = \"roberta-base\",DISTILBERT_U, DISTILBERT_C, DEBERTA_V2_XL, DEBERTA_V2_XXL      \n","TRAIN_SPLIT = 0.90\n","RANDOM_SEED = 42\n","BATCH_SIZES=1\n","EPOCHS = 10\n","FEATURE_CLASS_LABELS = cwd+\"/feature_class_labels.json\"\n","TEMP_MODEL_OUTPUT_DIR = cwd+'temp_model_output_dir'\n","TRAIN = 1\n","LR=0.0000075\n","\n","\n","BUILD_MODEL(DATASETS=DATASETS,\n","            MODEL_NAME=MODEL_NAME,\n","            TRAIN_SPLIT=TRAIN_SPLIT,\n","            RANDOM_SEED=RANDOM_SEED,\n","            BATCH_SIZES=BATCH_SIZES,\n","            EPOCHS=EPOCHS,\n","            FEATURE_CLASS_LABELS = FEATURE_CLASS_LABELS,\n","            TEMP_MODEL_OUTPUT_DIR=TEMP_MODEL_OUTPUT_DIR,\n","            TRAIN=TRAIN,\n","            LR=LR).TRAINING()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["21b6621819f349d99586e02e724cbeb7","e0115f5825fa4feeabc1fbebfd7c065d","a5da34360f0f41a2ae92bb36e01ef9bc","0d095351380e43e3ac013cf089baf7aa","a19ad2db346d4588a8d14646e829b921","2688cb7cde5a42aa996d08dbf7e79b7b","7562a41050734b63a1b8fafddb2a3039","7b0b099b63fc4316a1a37bdbe11badff","64d915c43d4a47c2aab6f24f5ccb733a","1d099d3751344349b7c8afcd8081a2a5","465caacbaa424370b67eaaf8be369f2a","7ef11409cd4c4886864f68d76e24326b","45f7f18e59de496da1baa8d6af6c2524","c34ed7b3a2ee446ca21fa926c85eb860","f8a425c78c9f4ee090913b108cad2189","482b61e0aac548f6bf003ae65e70a249","5e12f77930444a6b8e9c672b33379ed5","11ace536c40f403f95595e30b698b3dc","30a4d30de0264c6bbe851dbd135cabf6","9a6087817cd0417599c7857fbdac0171","2098dc71a4b84b4d8179b7ced941c529","fb94372c47b4472aaeb2a850eb979c9d","5a1e0739bd184ac5bfa1cbb73a981a8d","37a9ea83edd345738c80ee1441c37032","2f262daa75d8402fa0ef56674d56ad6c","5bd04a00dbf54eb99ed8a86ac070dd54","376d0ee1a5f643a394a8e8a327f90ca6","b252193f3a8644a3a26681358a17b8a3","ce0ddc0ccbe54759872b1472e3271f69","aa61821497f34a3c9f404f4be73e6069","78fa0eb3f3e24ee1a1e3e1440b83f56c","35f1ced51cad430aa21ac30a9a8ab6d1","540dd6735fb046eda022519371bdf8d2","23f2ef9163ee4b7fb3a2f5827135b515","c0b9718b6a5344db80c6a4ee1e887d68","c21fccaeb9af434a8107ee7ea5549857","2947debcbe3e41c3b4feb3734c82a700","cb262904e0334e1293b3dc2d43920cbd","019d792fb9d447198a130022417a0394","e15f6e9aff2548d9b9ff665a2985ded8","b602dae5fbf04ebaa321a071bfcc4ac3","b38279fe2a9f4f5192bbafd6860de5e3","09ef6e092c7b46a68fba3d26616dd37b","cd54527458534a1cbd037303d7f396fd","5ad1fffc971f453fb4084068a35153eb","3e49cc0ae5f743c6b96ea6337e8b1b4c","73229481969c4ee588d4354a0f0d17ef","e3a0d41937004ed398d7942aecf5b85b","7ee000e68dbb46d783343911801d8009","d96c105297984d0da8568920700e2624","5930045583e04e299937c344b947ceb4","b7f78b4507404662b2026a5014010f85","2da45c289c48491f9064496fa05fe609","a40efa3e751844508482282878401739","19ac6a104bc241e5b82a7b55d146a862","2576c7cef8f847788e2ac15ab2549e1f","492d90b36a394155bc58517758f27b69","1affcdbddd544bff8d81129c102915ff","18d66aca06f4475c9e9219f8fc8d77ef","111fe93718d641d086e84e4df65db2ce","bbd1f645f4e643e29cdf7465c0347c68","096646db5e2b43559df258e57ce200a0","d5dd14ccac6441ca91b79b52bb6be87c","b22daf273b514210b14780be7f97b566","b2bcb99c9adc45babf9de832ca52e85b","5d6fb48380274c85b9125616d058be59","1baf7e28c7094fddbdaa88be65de2104","50e7dac4affd48419c54219ba38439bd","ce3c3bca1a0d421fa496be803f464335","3105a2b1dbc8495c892832584493c3ee","4cff0bd98ddb4e64906693f708401ca7","cfada4a5a9c84f4385cbbdedf77ddd24","c70e83860c0841069f8aaff558aa9fce","18d4219fce344f9998f866509e3b385f","02bad0f95311451a847abbf6765de38d","c0b0b93a319840b2a273e2e10ea3404d","27a477015abd41339caee4b4f435f580"]},"executionInfo":{"status":"ok","timestamp":1684779062584,"user_tz":-300,"elapsed":199239,"user":{"displayName":"Abid Hussain","userId":"09813020101850201886"}},"outputId":"eba4588e-c677-43a8-dd49-cf97c10ee97b","id":"PKoabMcdpLTV"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.arrow_dataset:Loading cached split indices for dataset at /root/.cache/huggingface/datasets/json/default-702f038ab1acf893/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-ad7f61e4e51f8372.arrow and /root/.cache/huggingface/datasets/json/default-702f038ab1acf893/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-2b4d212ce9922787.arrow\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21b6621819f349d99586e02e724cbeb7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ef11409cd4c4886864f68d76e24326b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a1e0739bd184ac5bfa1cbb73a981a8d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)/main/tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"23f2ef9163ee4b7fb3a2f5827135b515"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/282 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ad1fffc971f453fb4084068a35153eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/32 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2576c7cef8f847788e2ac15ab2549e1f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/263M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1baf7e28c7094fddbdaa88be65de2104"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForTokenClassification: ['vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight']\n","- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["The maximum learning rate is:  7.5e-06\n","STARTING TRAINING----\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.3"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/CUAD_NER_TRANSFORMERS/wandb/run-20230522_180747-wozlljmb</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/engr2243/%27P2D-NER-2021%27/runs/wozlljmb' target=\"_blank\">distilbert-base-cased-22-05-2023</a></strong> to <a href='https://wandb.ai/engr2243/%27P2D-NER-2021%27' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/engr2243/%27P2D-NER-2021%27' target=\"_blank\">https://wandb.ai/engr2243/%27P2D-NER-2021%27</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/engr2243/%27P2D-NER-2021%27/runs/wozlljmb' target=\"_blank\">https://wandb.ai/engr2243/%27P2D-NER-2021%27/runs/wozlljmb</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2820' max='2820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2820/2820 03:05, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","      <th>Accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.137500</td>\n","      <td>0.288827</td>\n","      <td>0.069519</td>\n","      <td>0.070270</td>\n","      <td>0.069892</td>\n","      <td>0.905307</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.189900</td>\n","      <td>0.135344</td>\n","      <td>0.563452</td>\n","      <td>0.600000</td>\n","      <td>0.581152</td>\n","      <td>0.957412</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.102300</td>\n","      <td>0.098185</td>\n","      <td>0.610577</td>\n","      <td>0.686486</td>\n","      <td>0.646310</td>\n","      <td>0.969189</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.070000</td>\n","      <td>0.085910</td>\n","      <td>0.729592</td>\n","      <td>0.772973</td>\n","      <td>0.750656</td>\n","      <td>0.977254</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.048700</td>\n","      <td>0.081796</td>\n","      <td>0.787565</td>\n","      <td>0.821622</td>\n","      <td>0.804233</td>\n","      <td>0.979190</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>0.038200</td>\n","      <td>0.085711</td>\n","      <td>0.798942</td>\n","      <td>0.816216</td>\n","      <td>0.807487</td>\n","      <td>0.979513</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>0.034600</td>\n","      <td>0.084656</td>\n","      <td>0.796875</td>\n","      <td>0.827027</td>\n","      <td>0.811671</td>\n","      <td>0.979029</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>0.034100</td>\n","      <td>0.086139</td>\n","      <td>0.770408</td>\n","      <td>0.816216</td>\n","      <td>0.792651</td>\n","      <td>0.978222</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>0.034700</td>\n","      <td>0.086132</td>\n","      <td>0.761421</td>\n","      <td>0.810811</td>\n","      <td>0.785340</td>\n","      <td>0.979029</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>0.032900</td>\n","      <td>0.088825</td>\n","      <td>0.761421</td>\n","      <td>0.810811</td>\n","      <td>0.785340</td>\n","      <td>0.978222</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["TRAINING COMPLETED\n","STARTING EVALUATION ON CHOSEN EPOCH---\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [32/32 00:00]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["EVALUATION FINISHED---\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    </style>\n","<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▆▇████████</td></tr><tr><td>eval/f1</td><td>▁▆▆▇███████</td></tr><tr><td>eval/loss</td><td>█▃▂▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/precision</td><td>▁▆▆▇███████</td></tr><tr><td>eval/recall</td><td>▁▆▇████████</td></tr><tr><td>eval/runtime</td><td>▃▁█▆▂▂▂▁▁▂█</td></tr><tr><td>eval/samples_per_second</td><td>▆█▁▃▆▇▇██▇▁</td></tr><tr><td>eval/steps_per_second</td><td>▆█▁▃▆▇▇██▇▁</td></tr><tr><td>train/epoch</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▃▃▃▄▄▅▅▆▆▆▆▇▇████</td></tr><tr><td>train/learning_rate</td><td>▅█▇▆▃▂▁▂▃▆</td></tr><tr><td>train/loss</td><td>█▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.97903</td></tr><tr><td>eval/f1</td><td>0.81167</td></tr><tr><td>eval/loss</td><td>0.08466</td></tr><tr><td>eval/precision</td><td>0.79688</td></tr><tr><td>eval/recall</td><td>0.82703</td></tr><tr><td>eval/runtime</td><td>0.4958</td></tr><tr><td>eval/samples_per_second</td><td>64.542</td></tr><tr><td>eval/steps_per_second</td><td>64.542</td></tr><tr><td>train/epoch</td><td>10.0</td></tr><tr><td>train/global_step</td><td>2820</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.0329</td></tr><tr><td>train/total_flos</td><td>201844112204460.0</td></tr><tr><td>train/train_loss</td><td>0.17229</td></tr><tr><td>train/train_runtime</td><td>187.8118</td></tr><tr><td>train/train_samples_per_second</td><td>15.015</td></tr><tr><td>train/train_steps_per_second</td><td>15.015</td></tr></table><br/></div></div>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run <strong style=\"color:#cdcd00\">distilbert-base-cased-22-05-2023</strong> at: <a href='https://wandb.ai/engr2243/%27P2D-NER-2021%27/runs/wozlljmb' target=\"_blank\">https://wandb.ai/engr2243/%27P2D-NER-2021%27/runs/wozlljmb</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Find logs at: <code>./wandb/run-20230522_180747-wozlljmb/logs</code>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving model...\n","Saved_model model...\n"]}]},{"cell_type":"markdown","source":["## TEST-4"],"metadata":{"id":"GFSgHEGfpnQ8"}},{"cell_type":"code","source":["DATASETS = datasets\n","MODEL_NAME = \"DEBERTA_V2_XL\" #CHOOSE FROM ROBERTA = \"roberta-base\",DISTILBERT_U, DISTILBERT_C, DEBERTA_V2_XL, DEBERTA_V2_XXL      \n","TRAIN_SPLIT = 0.90\n","RANDOM_SEED = 42\n","BATCH_SIZES=1\n","EPOCHS = 10\n","FEATURE_CLASS_LABELS = cwd+\"/feature_class_labels.json\"\n","TEMP_MODEL_OUTPUT_DIR = cwd+'temp_model_output_dir'\n","TRAIN = 1\n","LR=0.0000075\n","\n","\n","BUILD_MODEL(DATASETS=DATASETS,\n","            MODEL_NAME=MODEL_NAME,\n","            TRAIN_SPLIT=TRAIN_SPLIT,\n","            RANDOM_SEED=RANDOM_SEED,\n","            BATCH_SIZES=BATCH_SIZES,\n","            EPOCHS=EPOCHS,\n","            FEATURE_CLASS_LABELS = FEATURE_CLASS_LABELS,\n","            TEMP_MODEL_OUTPUT_DIR=TEMP_MODEL_OUTPUT_DIR,\n","            TRAIN=TRAIN,\n","            LR=LR).TRAINING()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["a4ed779e02fc44669901f5e6574cbd71","72806808a63a4ae689b851cb6c744fbe","181666d29ecf462d8389cd5a0786634c","7907bb43495c497993044ffe87ebe339","78c572e1c1ad477cbb08d235fa4fadf5","f0c9f0ff3daf4c25bdc21bb1b2bfaeef","afca2c70a96b4d258595eb70433dfcaa","95680ae5f4f6471caccede438cfba032","71d6a0fdc548489b91c223b48d54bc17","d43b01aab86041f285302c4bb9c2c72b","a1193e11beeb43d1af35f2a62706498e","a6a2a19495904daa987987f2c74ff979","ec30ce2ea99f4e4584faedee778f009e","3cfcbe65b27d4911950c742cbd96bb76","2629cdd7c13240e5a9507d509bbc0724","ef7e10169efd4f788a059d1871b3956f","09c2c1edea5a45b98abcd6a309326644","3c4262cae7984bd99137d215643d6b96","7e02614997884a04a2dedbd0291c57dd","2ee13567cf0f449592b10c0e061904c4","7c858b5a681145df9dd1a9a25e4d515e","db2db7c32ba64b21868916377603c4df"]},"executionInfo":{"status":"error","timestamp":1684779913220,"user_tz":-300,"elapsed":20690,"user":{"displayName":"Abid Hussain","userId":"09813020101850201886"}},"outputId":"44ac2625-ad0f-4abe-e6fa-23897b86eef8","id":"KUBcFADipnRD"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.arrow_dataset:Loading cached split indices for dataset at /root/.cache/huggingface/datasets/json/default-702f038ab1acf893/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-ad7f61e4e51f8372.arrow and /root/.cache/huggingface/datasets/json/default-702f038ab1acf893/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-2b4d212ce9922787.arrow\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/282 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4ed779e02fc44669901f5e6574cbd71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/32 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6a2a19495904daa987987f2c74ff979"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at microsoft/deberta-v2-xlarge were not used when initializing DebertaV2ForTokenClassification: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'deberta.embeddings.position_embeddings.weight']\n","- This IS expected if you are initializing DebertaV2ForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2ForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/deberta-v2-xlarge and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["The maximum learning rate is:  7.5e-06\n","STARTING TRAINING----\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.15.3"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/CUAD_NER_TRANSFORMERS/wandb/run-20230522_182503-4jsnowul</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/engr2243/%27P2D-NER-2021%27/runs/4jsnowul' target=\"_blank\">microsoft/deberta-v2-xlarge-22-05-2023</a></strong> to <a href='https://wandb.ai/engr2243/%27P2D-NER-2021%27' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/engr2243/%27P2D-NER-2021%27' target=\"_blank\">https://wandb.ai/engr2243/%27P2D-NER-2021%27</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/engr2243/%27P2D-NER-2021%27/runs/4jsnowul' target=\"_blank\">https://wandb.ai/engr2243/%27P2D-NER-2021%27/runs/4jsnowul</a>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2' max='2820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [   2/2820 : < :, Epoch 0.00/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92m<cell line: 13>\u001b[0m:\u001b[94m22\u001b[0m                                                                            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92mTRAINING\u001b[0m:\u001b[94m278\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1664\u001b[0m in \u001b[92mtrain\u001b[0m                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1661 \u001b[0m\u001b[2m│   │   \u001b[0minner_training_loop = find_executable_batch_size(                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1662 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._inner_training_loop, \u001b[96mself\u001b[0m._train_batch_size, args.auto_find_batch_size  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1663 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1664 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m inner_training_loop(                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1665 \u001b[0m\u001b[2m│   │   │   \u001b[0margs=args,                                                                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1666 \u001b[0m\u001b[2m│   │   │   \u001b[0mresume_from_checkpoint=resume_from_checkpoint,                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1667 \u001b[0m\u001b[2m│   │   │   \u001b[0mtrial=trial,                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1940\u001b[0m in \u001b[92m_inner_training_loop\u001b[0m     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1937 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mwith\u001b[0m model.no_sync():                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1938 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mtr_loss_step = \u001b[96mself\u001b[0m.training_step(model, inputs)                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1939 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1940 \u001b[2m│   │   │   │   │   \u001b[0mtr_loss_step = \u001b[96mself\u001b[0m.training_step(model, inputs)                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1941 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1942 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m (                                                                      \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m1943 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0margs.logging_nan_inf_filter                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m2753\u001b[0m in \u001b[92mtraining_step\u001b[0m            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2750 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# loss gets scaled under gradient_accumulation_steps in deepspeed\u001b[0m             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2751 \u001b[0m\u001b[2m│   │   │   \u001b[0mloss = \u001b[96mself\u001b[0m.deepspeed.backward(loss)                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2752 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2753 \u001b[2m│   │   │   \u001b[0mloss.backward()                                                               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2754 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2755 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m loss.detach()                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m2756 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/\u001b[0m\u001b[1;33m_tensor.py\u001b[0m:\u001b[94m487\u001b[0m in \u001b[92mbackward\u001b[0m                         \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 484 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mcreate_graph=create_graph,                                                \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 485 \u001b[0m\u001b[2m│   │   │   │   \u001b[0minputs=inputs,                                                            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 486 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 487 \u001b[2m│   │   \u001b[0mtorch.autograd.backward(                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 488 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m, gradient, retain_graph, create_graph, inputs=inputs                     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 489 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 490 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/usr/local/lib/python3.10/dist-packages/torch/autograd/\u001b[0m\u001b[1;33m__init__.py\u001b[0m:\u001b[94m200\u001b[0m in \u001b[92mbackward\u001b[0m               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m197 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# The reason we repeat same the comment below is that\u001b[0m                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m198 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# some Python versions print out the first line of a multi-line function\u001b[0m               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m199 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# calls in the traceback and some print out the last line\u001b[0m                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m200 \u001b[2m│   \u001b[0mVariable._execution_engine.run_backward(  \u001b[2m# Calls into the C++ engine to run the bac\u001b[0m   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m201 \u001b[0m\u001b[2m│   │   \u001b[0mtensors, grad_tensors_, retain_graph, create_graph, inputs,                        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m202 \u001b[0m\u001b[2m│   │   \u001b[0mallow_unreachable=\u001b[94mTrue\u001b[0m, accumulate_grad=\u001b[94mTrue\u001b[0m)  \u001b[2m# Calls into the C++ engine to ru\u001b[0m   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m203 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n","\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n","\u001b[1;91mOutOfMemoryError: \u001b[0mCUDA out of memory. Tried to allocate \u001b[1;36m752.00\u001b[0m MiB \u001b[1m(\u001b[0mGPU \u001b[1;36m0\u001b[0m; \u001b[1;36m14.75\u001b[0m GiB total capacity; \u001b[1;36m12.47\u001b[0m GiB \n","already allocated; \u001b[1;36m252.81\u001b[0m MiB free; \u001b[1;36m13.45\u001b[0m GiB reserved in total by PyTorch\u001b[1m)\u001b[0m If reserved memory is >> allocated \n","memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n","PYTORCH_CUDA_ALLOC_CONF\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;cell line: 13&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">22</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">TRAINING</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">278</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1664</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1661 │   │   </span>inner_training_loop = find_executable_batch_size(                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1662 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._inner_training_loop, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._train_batch_size, args.auto_find_batch_size  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1663 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1664 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> inner_training_loop(                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1665 │   │   │   </span>args=args,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1666 │   │   │   </span>resume_from_checkpoint=resume_from_checkpoint,                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1667 │   │   │   </span>trial=trial,                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1940</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_training_loop</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1937 │   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> model.no_sync():                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1938 │   │   │   │   │   │   </span>tr_loss_step = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.training_step(model, inputs)                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1939 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1940 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>tr_loss_step = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.training_step(model, inputs)                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1941 │   │   │   │   </span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1942 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> (                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1943 │   │   │   │   │   </span>args.logging_nan_inf_filter                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2753</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">training_step</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2750 │   │   │   # loss gets scaled under gradient_accumulation_steps in deepspeed</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2751 │   │   │   </span>loss = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.deepspeed.backward(loss)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2752 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2753 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>loss.backward()                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2754 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2755 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> loss.detach()                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2756 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_tensor.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">487</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 484 │   │   │   │   </span>create_graph=create_graph,                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 485 │   │   │   │   </span>inputs=inputs,                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 486 │   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 487 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>torch.autograd.backward(                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 488 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, gradient, retain_graph, create_graph, inputs=inputs                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 489 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 490 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/usr/local/lib/python3.10/dist-packages/torch/autograd/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">__init__.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">200</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">backward</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">197 │   # The reason we repeat same the comment below is that</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">198 │   # some Python versions print out the first line of a multi-line function</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">199 │   # calls in the traceback and some print out the last line</span>                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>200 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>Variable._execution_engine.run_backward(  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine to run the bac</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">201 │   │   </span>tensors, grad_tensors_, retain_graph, create_graph, inputs,                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">202 │   │   </span>allow_unreachable=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>, accumulate_grad=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Calls into the C++ engine to ru</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">203 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n","<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">OutOfMemoryError: </span>CUDA out of memory. Tried to allocate <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">752.00</span> MiB <span style=\"font-weight: bold\">(</span>GPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.75</span> GiB total capacity; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12.47</span> GiB \n","already allocated; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">252.81</span> MiB free; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13.45</span> GiB reserved in total by PyTorch<span style=\"font-weight: bold\">)</span> If reserved memory is &gt;&gt; allocated \n","memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n","PYTORCH_CUDA_ALLOC_CONF\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["# Documents(s) Inference\n"],"metadata":{"id":"BowLU1Oqh1n-"}},{"cell_type":"code","source":["import os\n","os.chdir(\"/content/drive/MyDrive/CUAD_NER_TRANSFORMERS/\")\n","cwd = os.getcwd()\n","\n","from spacy.lang.en import English\n","from datasets import Dataset, DatasetDict\n","from collections import defaultdict\n","\n","nlp = English()\n","\n","class INFERENCE:\n","  def __init__(self, LST, MODEL_NAME, FEATURE_CLASS_LABELS, TEMP_MODEL_OUTPUT_DIR, BATCH_SIZES, RANDOM_SEED):\n","    self.LST = LST\n","\n","    self.MODEL_NAME = MODEL_NAME\n","    self.FEATURE_CLASS_LABELS = FEATURE_CLASS_LABELS\n","    self.BATCH_SIZES = BATCH_SIZES\n","    self.RANDOM_SEED = RANDOM_SEED\n","\n","    #List of labels saved in the data preparation stage\n","    self.label_list = self.load_labels_list(FEATURE_CLASS_LABELS)\n","\n","    #Models to test: Update as required\n","    self.models = dict(\n","        ROBERTA = \"roberta-base\",\n","        DISTILBERT_U = \"distilbert-base-uncased\",\n","        DISTILBERT_C = \"distilbert-base-cased\",\n","        DEBERTA_V2_XL = \"microsoft/deberta-v2-xlarge\",\n","        DEBERTA_V2_XXL = \"microsoft/deberta-v2-xxlarge\")\n","    \n","    self.TEMP_MODEL_OUTPUT_DIR = TEMP_MODEL_OUTPUT_DIR\n","\n","  #Loads the list of labels\n","  def load_labels_list(self, FEATURE_CLASS_LABELS):\n","      # Open the label list created in pre-processing corresponding to the ner_tag indices\n","      with open(FEATURE_CLASS_LABELS, 'r') as f:\n","          label_list = json.load(f)\n","      return label_list\n","\n","  # Text cleaning function for standard PDF parsing workflow\n","  def clean(self, text):\n","      text = text.replace(\"\\n\", \" \")  # Simple replacement for \"\\n\"   \n","      text = text.replace(\"\\xa0\", \" \")  # Simple replacement for \"\\xa0\"\n","      text = text.replace(\"\\x0c\", \" \")  # Simple replacement for \"\\x0c\"\n","      \n","      regex = \"\\ \\.\\ \"\n","      subst = \".\"\n","      text = re.sub(regex, subst, text, 0)  # Get rid of multiple dots\n","          \n","      regex = \"_\"\n","      subst = \" \"\n","      text = re.sub(regex, subst, text, 0)  # Get rid of underscores\n","        \n","      regex = \"--+\"\n","      subst = \" \"\n","      text = re.sub(regex, subst, text, 0)   # Get rid of multiple dashes\n","          \n","      regex = \"\\*+\"\n","      subst = \"*\"\n","      text = re.sub(regex, subst, text, 0)  # Get rid of multiple stars\n","          \n","      regex = \"\\ +\"\n","      subst = \" \"\n","      text = re.sub(regex, subst, text, 0)  # Get rid of multiple whitespace\n","      \n","      text = text.strip()  #Strip leading and trailing whitespace\n","      return text\n","  \n","  def tokenize(self, text_df):\n","    # We tokenize each agreement prior to bringing into the transformer model\n","    # Create tokens using spaCy\n","    text_df['tokens'] = text_df['Short_Text'].apply(lambda x: nlp(x))\n","\n","    # Split tokens into a list ready for CSV\n","    text_df['split_tokens'] = text_df['tokens'].apply(lambda x: [tok.text for tok in x])\n","\n","    # Create dummy NER tags for alignment purposes (a bit lazy, but convinient)\n","    text_df['dummy_ner_tags'] = text_df['tokens'].apply(lambda x: [0 for tok in x])\n","\n","    # Serialise the data to JSON for archive\n","    export_columns = ['split_tokens', 'dummy_ner_tags']\n","    export_df = text_df[export_columns]\n","    ds = Dataset.from_pandas(export_df)\n","\n","    datasets = DatasetDict()\n","    datasets['inference'] = ds\n","\n","    # export_df.to_json(TEST_DATA_FILE, orient=\"table\", index=False)\n","    text_df = text_df.drop(['dummy_ner_tags'], axis=1)\n","\n","    # Re-import the serialized JSON data and create a dataset in the format needed for the transformer\n","    return datasets, text_df\n","\n","\n","#==================DATA PREPROCESSING AND TOKENIZATION=========================#\n","  def word_id_func(self, input_ids, tokenizer, print_labs=False):\n","      tokens = tokenizer.convert_ids_to_tokens(input_ids)\n","      \n","      word_ids = []\n","      i=0\n","      spec_toks = ['[CLS]', '[SEP]', '[PAD]']\n","      for t in tokens:\n","          if t in spec_toks:\n","              word_ids.append(-100)\n","              print(t, i) if print_labs else None\n","          elif t.startswith('▁'):\n","              i += 1\n","              word_ids.append(i)\n","              print(t, i) if print_labs else None\n","          else:\n","              word_ids.append(i)\n","              print(t, i) if print_labs else None\n","          print(\"Total:\", i) if print_labs else None\n","      return word_ids\n","\n","  def tokenize_and_align_labels(self, examples, tokenizer,  label_all_tokens=False):\n","      tokenized_inputs = tokenizer(examples[\"split_tokens\"],\n","                                  truncation=True,\n","                                  is_split_into_words=True)\n","      labels = []\n","      for i, label in enumerate(examples[\"dummy_ner_tags\"]):\n","          word_ids = tokenized_inputs.word_ids(batch_index=i)\n","          previous_word_idx = None\n","          label_ids = []\n","          for word_idx in word_ids:\n","              # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n","              # ignored in the loss function.\n","              if word_idx is None:\n","                  label_ids.append(-100)\n","              # We set the label for the first token of each word.\n","              elif word_idx != previous_word_idx:\n","                  label_ids.append(label[word_idx])\n","              # For the other tokens in a word, we set the label to either the current label or -100, depending on\n","              # the label_all_tokens flag.\n","              else:\n","                  label_ids.append(label[word_idx] if label_all_tokens else -100)\n","              previous_word_idx = word_idx\n","          labels.append(label_ids)\n","\n","      tokenized_inputs[\"labels\"] = labels\n","      return tokenized_inputs\n","\n","  def tokenize_and_align_labels_deberta(self, examples, tokenizer, label_all_tokens=False):\n","      tokenized_inputs = tokenizer(examples[\"split_tokens\"],\n","                                  truncation=True,\n","                                  is_split_into_words=True)\n","      labels = []\n","      word_ids_list = []\n","      for input_ids in tokenized_inputs[\"input_ids\"]:\n","          wids = self.word_id_func(input_ids, tokenizer,  print_labs=False)\n","          word_ids_list.append(wids)\n","      \n","      for i, label in enumerate(examples[\"dummy_ner_tags\"]):\n","          word_ids = word_ids_list[i]\n","          previous_word_idx = None\n","          label_ids = []\n","          for word_idx in word_ids:\n","              # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n","              # ignored in the loss function.\n","              if word_idx == -100:\n","                  label_ids.append(-100)\n","              #We set the label for the first token of each word.\n","              elif word_idx != previous_word_idx:\n","                  label_ids.append(label[word_idx-1])\n","              # For the other tokens in a word, we set the label to either the current label or -100, depending on\n","              # the label_all_tokens flag.\n","              else:\n","                  label_ids.append(label[word_idx-1] if label_all_tokens else -100)\n","              previous_word_idx = word_idx\n","          labels.append(label_ids)\n","\n","      tokenized_inputs[\"labels\"] = labels\n","      return tokenized_inputs\n","#-------------------------------------------------------------------------------#\n","  def LOAD_MODEL(self, SAVED_MODEL, TOKENIZER, BATCH_SIZES, RANDOM_SEED):\n","    # Load the model and instantiate\n","    loaded_model = AutoModelForTokenClassification.from_pretrained(SAVED_MODEL)\n","\n","    args = TrainingArguments(output_dir = TEMP_MODEL_OUTPUT_DIR,\n","                            per_device_train_batch_size=BATCH_SIZES,\n","                            per_device_eval_batch_size=BATCH_SIZES,\n","                            seed=RANDOM_SEED\n","                            )\n","\n","    data_collator = DataCollatorForTokenClassification(TOKENIZER)\n","\n","    # Note instantiation currently takes a bit of time: https://github.com/huggingface/transformers/issues/9205\n","    # Instantiate the predictor\n","    pred_trainer = Trainer(\n","        loaded_model,\n","        args,\n","        data_collator=data_collator,\n","        tokenizer=TOKENIZER)\n","    return pred_trainer\n","  \n","  def GET_PREDICTIONS(self, text_df, pred_trainer, tokenized_datasets, label_list):\n","    # Extract the predictions\n","    predictions, labels, _ = pred_trainer.predict(tokenized_datasets[\"inference\"])\n","    predictions = np.argmax(predictions, axis=2)\n","    text_df['predictions'] = list(predictions)\n","\n","    # Remove ignored index (special tokens)\n","    true_predictions = [\n","        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n","        for prediction, label in zip(predictions, labels)\n","    ]\n","    text_df['true_predictions'] = true_predictions\n","    return text_df\n","\n","  # Consolidate all the information into the DataFrame\n","  def EXTRACT_DATA(self, tuple_list):\n","      de_list = []\n","      for tup in tuple_list:\n","          if tup[1] != 'O':\n","              de_list.append(tup)\n","      return de_list\n","\n","  #------------------------RETRIEVING INFORMATION-----------------------------#\n","  def extract_agreement_date(self, tuple_list):\n","      for d in tuple_list:\n","          if d[1] == \"B-AGMT_DATE\":\n","              temp_date=d[0]\n","          elif d[1] == \"I-AGMT_DATE\":\n","              temp_date = temp_date + \" \" + d[0]\n","          else:\n","              continue\n","      return temp_date\n","\n","\n","  def extract_agreement_name(self, tuple_list):\n","      for n in tuple_list:\n","          if n[1] == \"B-DOC_NAME\":\n","              temp_name=n[0]\n","          elif n[1] == \"I-DOC_NAME\":\n","              temp_name = temp_name + \" \" + n[0]\n","          else:\n","              continue\n","      return temp_name\n","  \n","\n","  def extract_agreement_parties(self, tuple_list):\n","      data_dict = defaultdict(list)\n","      for i, p in enumerate(tuple_list):\n","          if p[1] == \"B-PARTY\":\n","              temp_party=p[0]\n","              if i == (len(tuple_list)-1):\n","                  data_dict[\"Parties\"].append(temp_party)\n","              elif tuple_list[i+1][1] != \"I-PARTY\":\n","                  data_dict[\"Parties\"].append(temp_party)\n","          elif p[1] == \"I-PARTY\":\n","              temp_party = temp_party + \" \" + p[0]\n","              if i == (len(tuple_list)-1):\n","                  data_dict[\"Parties\"].append(temp_party)\n","              elif tuple_list[i+1][1] != \"I-PARTY\":\n","                  data_dict[\"Parties\"].append(temp_party)\n","\n","      return list(dict.fromkeys(data_dict['Parties']))\n","  #------------------------RETRIEVING INFORMATION-----------------------------#\n","\n","\n","  def RUN_INFERENCE(self):\n","    columns = ['File_Name','Full_Text']\n","    lst_docs = self.LST\n","    df = pd.DataFrame(lst_docs)\n","    df.columns = columns\n","    df['Short_Text'] = df.apply(lambda x: self.clean(x['Full_Text']), axis=1)\n","    datasets, df = self.tokenize(df)\n","    label_list = self.label_list\n","\n","    # WHICH PRE-TRAINED TRANSFORMER TO FINE-TUNE?\n","    models = self.models\n","    MODEL_CHECKPOINT = models[self.MODEL_NAME]\n","    SAVED_MODEL = cwd + f\"/models/p2d-NER-Fine-Tune-Transformer-{MODEL_CHECKPOINT}\" # Change for notebook version\n","\n","    # Instantiate the tokenizer\n","    #For RoBERTa-base, need to use RobertaTokenizerFast with add_prefix_space=True to use it with pretokenized inputs.\n","\n","    if MODEL_CHECKPOINT == models['ROBERTA']:\n","        tokenizer = RobertaTokenizerFast.from_pretrained(MODEL_CHECKPOINT, add_prefix_space=True)\n","    else:\n","        tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n","\n","    # To apply this function on all the words and labels in our dataset,\n","    # we just use the map method of our dataset object we created earlier.\n","\n","    # 🤗 Datasets warns you when it uses cached files, you can pass load_from_cache_file=False in the\n","    # call to map to not use the cached files and force the preprocessing to be applied again.\n","    if MODEL_CHECKPOINT == models['DEBERTA_V2_XL']:\n","        tokenize_and_align_labels = self.tokenize_and_align_labels_deberta\n","    else:\n","        tokenize_and_align_labels = self.tokenize_and_align_labels\n","\n","    tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True,\n","                                        load_from_cache_file=True,\n","                                        fn_kwargs={\"tokenizer\": tokenizer})\n","    \n","    pred_trainer = self.LOAD_MODEL(SAVED_MODEL=SAVED_MODEL, TOKENIZER=tokenizer,\n","                                   BATCH_SIZES = self.BATCH_SIZES,\n","                                   RANDOM_SEED = self.RANDOM_SEED)\n","    \n","    df = self.GET_PREDICTIONS(text_df = df, pred_trainer=pred_trainer,\n","                              tokenized_datasets = tokenized_datasets,\n","                              label_list = label_list)\n","    \n","    df['check_pred'] = list(list(zip(a,b)) for a,b in zip(df['split_tokens'], df['true_predictions']))\n","    df['data_tuples'] = df['check_pred'].apply(self.EXTRACT_DATA)\n","\n","    #FORMAT INFORMATIONS TAGGING\n","    df['agmt_name'] = df['data_tuples'].apply(self.extract_agreement_name)\n","    df['agmt_date'] = df['data_tuples'].apply(self.extract_agreement_date)\n","    df['agmt_parties'] = df['data_tuples'].apply(self.extract_agreement_parties)\n","\n","    # Create a dataframe with just the information we want to keep and \n","    df_ex = df[['File_Name', 'agmt_name', 'agmt_date', 'agmt_parties', 'Full_Text']].copy()\n","    df_ex = df_ex.sort_values('File_Name', axis=0)\n","    return df_ex"],"metadata":{"id":"ZeTXTV64h8Ko"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["path = \"/content/drive/MyDrive/CUAD_NER_TRANSFORMERS/CUAD_v1/full_contract_txt/ADMA BioManufacturing, LLC -  Amendment #3 to Manufacturing Agreement .txt\"\n","txt= open(path, 'r').read()\n","docs = [\n","    [\"1\", txt],\n","    ['2', txt]\n","    ]\n","MODEL_NAME = 'DISTILBERT_U' #CHOOSE FROM ROBERTA = \"roberta-base\",DISTILBERT_U, DISTILBERT_C, DEBERTA_V2_XL, DEBERTA_V2_XXL\n","FEATURE_CLASS_LABELS = \"/content/drive/MyDrive/CUAD_NER_TRANSFORMERS/feature_class_labels.json\"\n","TEMP_MODEL_OUTPUT_DIR = 'temp_model_output_dir'\n","BATCH_SIZES = 4\n","RANDOM_SEED = 42\n","\n","results=  INFERENCE(LST=docs, MODEL_NAME = MODEL_NAME,\n","                    FEATURE_CLASS_LABELS=FEATURE_CLASS_LABELS,\n","                    TEMP_MODEL_OUTPUT_DIR=TEMP_MODEL_OUTPUT_DIR,\n","                    BATCH_SIZES = BATCH_SIZES,\n","                    RANDOM_SEED = RANDOM_SEED).RUN_INFERENCE()\n","\n","results"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":149,"referenced_widgets":["11825d435d9c4a97beaa4238203e46e2","5e14b222a9a3417d913048d7b9ed71c8","50628320709d42a88c9ae657e4d99f02","10f4820e181d4523bf58a4b0bdd46c8d","9a6b299c74c34d19a9a586d71a08f209","675c7c813ec84e2fade7cfd50a2872b1","ba27e485d5bb488bb0b3f61b5b95fb25","26335f9d5c144b459ecc68239bfa625a","456f1489b02d465f80f231a13c8eaa17","90200e83d0924d1bacb603f4993cd2eb","fa9be888a1914c98ae4f111e233f30d9"]},"id":"dCofaBiKiajj","executionInfo":{"status":"ok","timestamp":1684780064239,"user_tz":-300,"elapsed":4416,"user":{"displayName":"Abid Hussain","userId":"09813020101850201886"}},"outputId":"7351d098-0de3-44c9-e6de-0e1508b7ab0f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/2 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11825d435d9c4a97beaa4238203e46e2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["  File_Name                agmt_name           agmt_date  \\\n","0         1  Manufacturing Agreement  December 21 , 2017   \n","1         2  Manufacturing Agreement  December 21 , 2017   \n","\n","                                        agmt_parties  \\\n","0  [ADMA BioManufacturing , LLC, Sanofi Pasteur S...   \n","1  [ADMA BioManufacturing , LLC, Sanofi Pasteur S...   \n","\n","                                           Full_Text  \n","0  Confidential treatment has been requested with...  \n","1  Confidential treatment has been requested with...  "],"text/html":["\n","  <div id=\"df-f5fd552c-664b-4f90-b9d4-ea83dce69a33\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>File_Name</th>\n","      <th>agmt_name</th>\n","      <th>agmt_date</th>\n","      <th>agmt_parties</th>\n","      <th>Full_Text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Manufacturing Agreement</td>\n","      <td>December 21 , 2017</td>\n","      <td>[ADMA BioManufacturing , LLC, Sanofi Pasteur S...</td>\n","      <td>Confidential treatment has been requested with...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Manufacturing Agreement</td>\n","      <td>December 21 , 2017</td>\n","      <td>[ADMA BioManufacturing , LLC, Sanofi Pasteur S...</td>\n","      <td>Confidential treatment has been requested with...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5fd552c-664b-4f90-b9d4-ea83dce69a33')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f5fd552c-664b-4f90-b9d4-ea83dce69a33 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f5fd552c-664b-4f90-b9d4-ea83dce69a33');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":[],"metadata":{"id":"INzAffn8Hx5p"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.8"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"9b63701a33ef426cb0bb9216f0cb7192":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5c1da94929f64828ac11e46e0d012f85","IPY_MODEL_0d11e3b721194fc59b79ff6bbf3d773c","IPY_MODEL_dc72b321379f4e3a8dad9df0491b9ec1"],"layout":"IPY_MODEL_aa75fea8697b452f8d6caef70fb679db"}},"5c1da94929f64828ac11e46e0d012f85":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6aa55213e0ca4d799b4221013445a15f","placeholder":"​","style":"IPY_MODEL_3282431008dc4325b9c5dd0cbdcdb20b","value":"100%"}},"0d11e3b721194fc59b79ff6bbf3d773c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_47125015657748dcaf3cea1528263c37","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3cd12af3fc5b42fea79376fee0368d51","value":1}},"dc72b321379f4e3a8dad9df0491b9ec1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa7480123fcc43a58c252ef363038bdf","placeholder":"​","style":"IPY_MODEL_7ad542532b1d4ccfaf3096f5f4754fcd","value":" 1/1 [00:00&lt;00:00, 43.12it/s]"}},"aa75fea8697b452f8d6caef70fb679db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6aa55213e0ca4d799b4221013445a15f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3282431008dc4325b9c5dd0cbdcdb20b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"47125015657748dcaf3cea1528263c37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3cd12af3fc5b42fea79376fee0368d51":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aa7480123fcc43a58c252ef363038bdf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7ad542532b1d4ccfaf3096f5f4754fcd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"43b9d17d3cbc49f98d54da8ac44f23bf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fce12e21d83649e8b850f87ba77d7bd2","IPY_MODEL_1afb83a3c5be4887b86060692e125553","IPY_MODEL_dcc9c5c391e846b7946b3fa359d871c0"],"layout":"IPY_MODEL_ad5261a8925b4afeaaa092af1fec2d20"}},"fce12e21d83649e8b850f87ba77d7bd2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fcf0571d52b54ad681c2a44578831170","placeholder":"​","style":"IPY_MODEL_8ed272c98d1b4ecbb662c78a11c09631","value":"Map: 100%"}},"1afb83a3c5be4887b86060692e125553":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c8f8d053f4f4729b550ed87318c8f14","max":282,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4e858979e07541a1b2ccb99e3c3de4e3","value":282}},"dcc9c5c391e846b7946b3fa359d871c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5a5950d57b848ae911670f4d05039aa","placeholder":"​","style":"IPY_MODEL_38e9041d08ee4de794c1e7e3047e2607","value":" 282/282 [00:00&lt;00:00, 911.47 examples/s]"}},"ad5261a8925b4afeaaa092af1fec2d20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"fcf0571d52b54ad681c2a44578831170":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ed272c98d1b4ecbb662c78a11c09631":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c8f8d053f4f4729b550ed87318c8f14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e858979e07541a1b2ccb99e3c3de4e3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d5a5950d57b848ae911670f4d05039aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38e9041d08ee4de794c1e7e3047e2607":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f31ee30cc021427481069f69774fa957":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_95dc445d782c41f5b397830c3bec78c5","IPY_MODEL_64569abcc17c4a44b3a116868f36f227","IPY_MODEL_0d5446d926cb4ab8b577d6a4ca1c2690"],"layout":"IPY_MODEL_66c8a05e6a1d4bdea692d0127621064e"}},"95dc445d782c41f5b397830c3bec78c5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8bc3eee1ec394b54bfd9b9bb673808a4","placeholder":"​","style":"IPY_MODEL_5b87173cfda14999986cc7c80fd224bd","value":"Map:   0%"}},"64569abcc17c4a44b3a116868f36f227":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad3dbc86fbe94526a6ee0acbd05eb8d2","max":32,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1dee7617de5c47f8ac7a22d71815d493","value":32}},"0d5446d926cb4ab8b577d6a4ca1c2690":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_652de661cdc94d179d59ff713ffde6cf","placeholder":"​","style":"IPY_MODEL_510f4f03f609444b83cf1b103a77b8f2","value":" 0/32 [00:00&lt;?, ? examples/s]"}},"66c8a05e6a1d4bdea692d0127621064e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"8bc3eee1ec394b54bfd9b9bb673808a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5b87173cfda14999986cc7c80fd224bd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad3dbc86fbe94526a6ee0acbd05eb8d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1dee7617de5c47f8ac7a22d71815d493":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"652de661cdc94d179d59ff713ffde6cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"510f4f03f609444b83cf1b103a77b8f2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"45b622e410b94cbb81edbb9b0d3d0011":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_b682ddee653b4d7282531a431a83bddd","IPY_MODEL_eee709fc357d4d8ab6087d45b4555567"],"layout":"IPY_MODEL_47ba3478c8c0440498920debd931154a"}},"b682ddee653b4d7282531a431a83bddd":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e17f1db76d24534b89e98dfbbd7edff","placeholder":"​","style":"IPY_MODEL_6129ea2bc3b447989aaee16a56fc7420","value":"0.001 MB of 0.019 MB uploaded (0.000 MB deduped)\r"}},"eee709fc357d4d8ab6087d45b4555567":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_3d4f0e33499a4cbb9e4e54e130c9ba68","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ee5fecdb0c6842229dae6dd563ce763b","value":0.06789942275706878}},"47ba3478c8c0440498920debd931154a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e17f1db76d24534b89e98dfbbd7edff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6129ea2bc3b447989aaee16a56fc7420":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3d4f0e33499a4cbb9e4e54e130c9ba68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee5fecdb0c6842229dae6dd563ce763b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"524cf5389f0e4389bb98a0eb5fcd402b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ab4bed901b834ec893673faa45a4fced","IPY_MODEL_371bad6779cc4182a432512fa8fc2352","IPY_MODEL_63aa42397a6c496eb1eb3089fd3c96de"],"layout":"IPY_MODEL_45ef8569369f41e0a0f2b54560b299f8"}},"ab4bed901b834ec893673faa45a4fced":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5078c296a59443e2b12f08aeb122645c","placeholder":"​","style":"IPY_MODEL_e212308a0a27479f9b9cd7727a59837e","value":"Map: 100%"}},"371bad6779cc4182a432512fa8fc2352":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_81fa2bad7c26428f96f3593ba6259459","max":282,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5ca2f05d6821428a8362bddc99778e9d","value":282}},"63aa42397a6c496eb1eb3089fd3c96de":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4933be1250784e1e865e92fe917670cd","placeholder":"​","style":"IPY_MODEL_14d8f31d7ecb470d8fcf1cbb53e66470","value":" 282/282 [00:00&lt;00:00, 813.14 examples/s]"}},"45ef8569369f41e0a0f2b54560b299f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"5078c296a59443e2b12f08aeb122645c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e212308a0a27479f9b9cd7727a59837e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"81fa2bad7c26428f96f3593ba6259459":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ca2f05d6821428a8362bddc99778e9d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4933be1250784e1e865e92fe917670cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14d8f31d7ecb470d8fcf1cbb53e66470":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b654246a4e28452d8e3265b13812ca51":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7e3cee45b58446e28854156c400dd0ae","IPY_MODEL_992420820c714368bf2d3b54edfb9e7e","IPY_MODEL_2a508ae050cd4f68a10962a0c5a061a7"],"layout":"IPY_MODEL_73abe7dd90f54d349423c24b07d48644"}},"7e3cee45b58446e28854156c400dd0ae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_74c88a9876294f8cbdac4dfa42058c5e","placeholder":"​","style":"IPY_MODEL_67b5fe76480141ab9d728cbd7509ce2d","value":"Map:   0%"}},"992420820c714368bf2d3b54edfb9e7e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ef3d85520534f8b955f4505021fb090","max":32,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9ecbabeeb4af46869c0246d409cf0f5c","value":32}},"2a508ae050cd4f68a10962a0c5a061a7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_961a955d107744a3897bf1074d89088c","placeholder":"​","style":"IPY_MODEL_a0ca00e01e964befb7f0cdfd490f86a6","value":" 0/32 [00:00&lt;?, ? examples/s]"}},"73abe7dd90f54d349423c24b07d48644":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"74c88a9876294f8cbdac4dfa42058c5e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67b5fe76480141ab9d728cbd7509ce2d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5ef3d85520534f8b955f4505021fb090":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9ecbabeeb4af46869c0246d409cf0f5c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"961a955d107744a3897bf1074d89088c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0ca00e01e964befb7f0cdfd490f86a6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c5c74f68f08c4381b4898b9d9af1cc75":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_0202f7938b934c70a9eca787efa24b95","IPY_MODEL_888c57b882cf4ab7ae9c1ef758f6613b"],"layout":"IPY_MODEL_be01eea9866240aaac4e5dc06d785683"}},"0202f7938b934c70a9eca787efa24b95":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_88204526bf504876a30d5eefc76b93aa","placeholder":"​","style":"IPY_MODEL_6356fcf32fe14e2a8abc69562738958d","value":"0.001 MB of 0.019 MB uploaded (0.000 MB deduped)\r"}},"888c57b882cf4ab7ae9c1ef758f6613b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_c014ffe390d8456dbce26372e7d3c8ea","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1d61df64ed324eafb3139f76cb964ef0","value":0.06809701492537314}},"be01eea9866240aaac4e5dc06d785683":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88204526bf504876a30d5eefc76b93aa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6356fcf32fe14e2a8abc69562738958d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c014ffe390d8456dbce26372e7d3c8ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1d61df64ed324eafb3139f76cb964ef0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"21b6621819f349d99586e02e724cbeb7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e0115f5825fa4feeabc1fbebfd7c065d","IPY_MODEL_a5da34360f0f41a2ae92bb36e01ef9bc","IPY_MODEL_0d095351380e43e3ac013cf089baf7aa"],"layout":"IPY_MODEL_a19ad2db346d4588a8d14646e829b921"}},"e0115f5825fa4feeabc1fbebfd7c065d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2688cb7cde5a42aa996d08dbf7e79b7b","placeholder":"​","style":"IPY_MODEL_7562a41050734b63a1b8fafddb2a3039","value":"Downloading (…)okenizer_config.json: 100%"}},"a5da34360f0f41a2ae92bb36e01ef9bc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b0b099b63fc4316a1a37bdbe11badff","max":29,"min":0,"orientation":"horizontal","style":"IPY_MODEL_64d915c43d4a47c2aab6f24f5ccb733a","value":29}},"0d095351380e43e3ac013cf089baf7aa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d099d3751344349b7c8afcd8081a2a5","placeholder":"​","style":"IPY_MODEL_465caacbaa424370b67eaaf8be369f2a","value":" 29.0/29.0 [00:00&lt;00:00, 2.57kB/s]"}},"a19ad2db346d4588a8d14646e829b921":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2688cb7cde5a42aa996d08dbf7e79b7b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7562a41050734b63a1b8fafddb2a3039":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b0b099b63fc4316a1a37bdbe11badff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64d915c43d4a47c2aab6f24f5ccb733a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1d099d3751344349b7c8afcd8081a2a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"465caacbaa424370b67eaaf8be369f2a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ef11409cd4c4886864f68d76e24326b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_45f7f18e59de496da1baa8d6af6c2524","IPY_MODEL_c34ed7b3a2ee446ca21fa926c85eb860","IPY_MODEL_f8a425c78c9f4ee090913b108cad2189"],"layout":"IPY_MODEL_482b61e0aac548f6bf003ae65e70a249"}},"45f7f18e59de496da1baa8d6af6c2524":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e12f77930444a6b8e9c672b33379ed5","placeholder":"​","style":"IPY_MODEL_11ace536c40f403f95595e30b698b3dc","value":"Downloading (…)lve/main/config.json: 100%"}},"c34ed7b3a2ee446ca21fa926c85eb860":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_30a4d30de0264c6bbe851dbd135cabf6","max":411,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9a6087817cd0417599c7857fbdac0171","value":411}},"f8a425c78c9f4ee090913b108cad2189":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2098dc71a4b84b4d8179b7ced941c529","placeholder":"​","style":"IPY_MODEL_fb94372c47b4472aaeb2a850eb979c9d","value":" 411/411 [00:00&lt;00:00, 38.0kB/s]"}},"482b61e0aac548f6bf003ae65e70a249":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e12f77930444a6b8e9c672b33379ed5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11ace536c40f403f95595e30b698b3dc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"30a4d30de0264c6bbe851dbd135cabf6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9a6087817cd0417599c7857fbdac0171":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2098dc71a4b84b4d8179b7ced941c529":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fb94372c47b4472aaeb2a850eb979c9d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a1e0739bd184ac5bfa1cbb73a981a8d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_37a9ea83edd345738c80ee1441c37032","IPY_MODEL_2f262daa75d8402fa0ef56674d56ad6c","IPY_MODEL_5bd04a00dbf54eb99ed8a86ac070dd54"],"layout":"IPY_MODEL_376d0ee1a5f643a394a8e8a327f90ca6"}},"37a9ea83edd345738c80ee1441c37032":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b252193f3a8644a3a26681358a17b8a3","placeholder":"​","style":"IPY_MODEL_ce0ddc0ccbe54759872b1472e3271f69","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"2f262daa75d8402fa0ef56674d56ad6c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aa61821497f34a3c9f404f4be73e6069","max":213450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_78fa0eb3f3e24ee1a1e3e1440b83f56c","value":213450}},"5bd04a00dbf54eb99ed8a86ac070dd54":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_35f1ced51cad430aa21ac30a9a8ab6d1","placeholder":"​","style":"IPY_MODEL_540dd6735fb046eda022519371bdf8d2","value":" 213k/213k [00:00&lt;00:00, 2.81MB/s]"}},"376d0ee1a5f643a394a8e8a327f90ca6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b252193f3a8644a3a26681358a17b8a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce0ddc0ccbe54759872b1472e3271f69":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aa61821497f34a3c9f404f4be73e6069":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78fa0eb3f3e24ee1a1e3e1440b83f56c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"35f1ced51cad430aa21ac30a9a8ab6d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"540dd6735fb046eda022519371bdf8d2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23f2ef9163ee4b7fb3a2f5827135b515":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c0b9718b6a5344db80c6a4ee1e887d68","IPY_MODEL_c21fccaeb9af434a8107ee7ea5549857","IPY_MODEL_2947debcbe3e41c3b4feb3734c82a700"],"layout":"IPY_MODEL_cb262904e0334e1293b3dc2d43920cbd"}},"c0b9718b6a5344db80c6a4ee1e887d68":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_019d792fb9d447198a130022417a0394","placeholder":"​","style":"IPY_MODEL_e15f6e9aff2548d9b9ff665a2985ded8","value":"Downloading (…)/main/tokenizer.json: 100%"}},"c21fccaeb9af434a8107ee7ea5549857":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b602dae5fbf04ebaa321a071bfcc4ac3","max":435797,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b38279fe2a9f4f5192bbafd6860de5e3","value":435797}},"2947debcbe3e41c3b4feb3734c82a700":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_09ef6e092c7b46a68fba3d26616dd37b","placeholder":"​","style":"IPY_MODEL_cd54527458534a1cbd037303d7f396fd","value":" 436k/436k [00:00&lt;00:00, 14.1MB/s]"}},"cb262904e0334e1293b3dc2d43920cbd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"019d792fb9d447198a130022417a0394":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e15f6e9aff2548d9b9ff665a2985ded8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b602dae5fbf04ebaa321a071bfcc4ac3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b38279fe2a9f4f5192bbafd6860de5e3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"09ef6e092c7b46a68fba3d26616dd37b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd54527458534a1cbd037303d7f396fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5ad1fffc971f453fb4084068a35153eb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3e49cc0ae5f743c6b96ea6337e8b1b4c","IPY_MODEL_73229481969c4ee588d4354a0f0d17ef","IPY_MODEL_e3a0d41937004ed398d7942aecf5b85b"],"layout":"IPY_MODEL_7ee000e68dbb46d783343911801d8009"}},"3e49cc0ae5f743c6b96ea6337e8b1b4c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d96c105297984d0da8568920700e2624","placeholder":"​","style":"IPY_MODEL_5930045583e04e299937c344b947ceb4","value":"Map: 100%"}},"73229481969c4ee588d4354a0f0d17ef":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_b7f78b4507404662b2026a5014010f85","max":282,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2da45c289c48491f9064496fa05fe609","value":282}},"e3a0d41937004ed398d7942aecf5b85b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a40efa3e751844508482282878401739","placeholder":"​","style":"IPY_MODEL_19ac6a104bc241e5b82a7b55d146a862","value":" 282/282 [00:00&lt;00:00, 947.33 examples/s]"}},"7ee000e68dbb46d783343911801d8009":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"d96c105297984d0da8568920700e2624":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5930045583e04e299937c344b947ceb4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b7f78b4507404662b2026a5014010f85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2da45c289c48491f9064496fa05fe609":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a40efa3e751844508482282878401739":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19ac6a104bc241e5b82a7b55d146a862":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2576c7cef8f847788e2ac15ab2549e1f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_492d90b36a394155bc58517758f27b69","IPY_MODEL_1affcdbddd544bff8d81129c102915ff","IPY_MODEL_18d66aca06f4475c9e9219f8fc8d77ef"],"layout":"IPY_MODEL_111fe93718d641d086e84e4df65db2ce"}},"492d90b36a394155bc58517758f27b69":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bbd1f645f4e643e29cdf7465c0347c68","placeholder":"​","style":"IPY_MODEL_096646db5e2b43559df258e57ce200a0","value":"Map:   0%"}},"1affcdbddd544bff8d81129c102915ff":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5dd14ccac6441ca91b79b52bb6be87c","max":32,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b22daf273b514210b14780be7f97b566","value":32}},"18d66aca06f4475c9e9219f8fc8d77ef":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b2bcb99c9adc45babf9de832ca52e85b","placeholder":"​","style":"IPY_MODEL_5d6fb48380274c85b9125616d058be59","value":" 0/32 [00:00&lt;?, ? examples/s]"}},"111fe93718d641d086e84e4df65db2ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"bbd1f645f4e643e29cdf7465c0347c68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"096646db5e2b43559df258e57ce200a0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d5dd14ccac6441ca91b79b52bb6be87c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b22daf273b514210b14780be7f97b566":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b2bcb99c9adc45babf9de832ca52e85b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d6fb48380274c85b9125616d058be59":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1baf7e28c7094fddbdaa88be65de2104":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_50e7dac4affd48419c54219ba38439bd","IPY_MODEL_ce3c3bca1a0d421fa496be803f464335","IPY_MODEL_3105a2b1dbc8495c892832584493c3ee"],"layout":"IPY_MODEL_4cff0bd98ddb4e64906693f708401ca7"}},"50e7dac4affd48419c54219ba38439bd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cfada4a5a9c84f4385cbbdedf77ddd24","placeholder":"​","style":"IPY_MODEL_c70e83860c0841069f8aaff558aa9fce","value":"Downloading pytorch_model.bin: 100%"}},"ce3c3bca1a0d421fa496be803f464335":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_18d4219fce344f9998f866509e3b385f","max":263273408,"min":0,"orientation":"horizontal","style":"IPY_MODEL_02bad0f95311451a847abbf6765de38d","value":263273408}},"3105a2b1dbc8495c892832584493c3ee":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0b0b93a319840b2a273e2e10ea3404d","placeholder":"​","style":"IPY_MODEL_27a477015abd41339caee4b4f435f580","value":" 263M/263M [00:01&lt;00:00, 142MB/s]"}},"4cff0bd98ddb4e64906693f708401ca7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfada4a5a9c84f4385cbbdedf77ddd24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c70e83860c0841069f8aaff558aa9fce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"18d4219fce344f9998f866509e3b385f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"02bad0f95311451a847abbf6765de38d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c0b0b93a319840b2a273e2e10ea3404d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27a477015abd41339caee4b4f435f580":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4ed779e02fc44669901f5e6574cbd71":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_72806808a63a4ae689b851cb6c744fbe","IPY_MODEL_181666d29ecf462d8389cd5a0786634c","IPY_MODEL_7907bb43495c497993044ffe87ebe339"],"layout":"IPY_MODEL_78c572e1c1ad477cbb08d235fa4fadf5"}},"72806808a63a4ae689b851cb6c744fbe":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f0c9f0ff3daf4c25bdc21bb1b2bfaeef","placeholder":"​","style":"IPY_MODEL_afca2c70a96b4d258595eb70433dfcaa","value":"Map: 100%"}},"181666d29ecf462d8389cd5a0786634c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_95680ae5f4f6471caccede438cfba032","max":282,"min":0,"orientation":"horizontal","style":"IPY_MODEL_71d6a0fdc548489b91c223b48d54bc17","value":282}},"7907bb43495c497993044ffe87ebe339":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d43b01aab86041f285302c4bb9c2c72b","placeholder":"​","style":"IPY_MODEL_a1193e11beeb43d1af35f2a62706498e","value":" 282/282 [00:00&lt;00:00, 680.37 examples/s]"}},"78c572e1c1ad477cbb08d235fa4fadf5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"f0c9f0ff3daf4c25bdc21bb1b2bfaeef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"afca2c70a96b4d258595eb70433dfcaa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95680ae5f4f6471caccede438cfba032":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71d6a0fdc548489b91c223b48d54bc17":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d43b01aab86041f285302c4bb9c2c72b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a1193e11beeb43d1af35f2a62706498e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a6a2a19495904daa987987f2c74ff979":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ec30ce2ea99f4e4584faedee778f009e","IPY_MODEL_3cfcbe65b27d4911950c742cbd96bb76","IPY_MODEL_2629cdd7c13240e5a9507d509bbc0724"],"layout":"IPY_MODEL_ef7e10169efd4f788a059d1871b3956f"}},"ec30ce2ea99f4e4584faedee778f009e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_09c2c1edea5a45b98abcd6a309326644","placeholder":"​","style":"IPY_MODEL_3c4262cae7984bd99137d215643d6b96","value":"Map:   0%"}},"3cfcbe65b27d4911950c742cbd96bb76":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e02614997884a04a2dedbd0291c57dd","max":32,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ee13567cf0f449592b10c0e061904c4","value":32}},"2629cdd7c13240e5a9507d509bbc0724":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c858b5a681145df9dd1a9a25e4d515e","placeholder":"​","style":"IPY_MODEL_db2db7c32ba64b21868916377603c4df","value":" 0/32 [00:00&lt;?, ? examples/s]"}},"ef7e10169efd4f788a059d1871b3956f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"09c2c1edea5a45b98abcd6a309326644":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c4262cae7984bd99137d215643d6b96":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7e02614997884a04a2dedbd0291c57dd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ee13567cf0f449592b10c0e061904c4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7c858b5a681145df9dd1a9a25e4d515e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db2db7c32ba64b21868916377603c4df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"11825d435d9c4a97beaa4238203e46e2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5e14b222a9a3417d913048d7b9ed71c8","IPY_MODEL_50628320709d42a88c9ae657e4d99f02","IPY_MODEL_10f4820e181d4523bf58a4b0bdd46c8d"],"layout":"IPY_MODEL_9a6b299c74c34d19a9a586d71a08f209"}},"5e14b222a9a3417d913048d7b9ed71c8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_675c7c813ec84e2fade7cfd50a2872b1","placeholder":"​","style":"IPY_MODEL_ba27e485d5bb488bb0b3f61b5b95fb25","value":"Map:   0%"}},"50628320709d42a88c9ae657e4d99f02":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_26335f9d5c144b459ecc68239bfa625a","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_456f1489b02d465f80f231a13c8eaa17","value":2}},"10f4820e181d4523bf58a4b0bdd46c8d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90200e83d0924d1bacb603f4993cd2eb","placeholder":"​","style":"IPY_MODEL_fa9be888a1914c98ae4f111e233f30d9","value":" 0/2 [00:00&lt;?, ? examples/s]"}},"9a6b299c74c34d19a9a586d71a08f209":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"675c7c813ec84e2fade7cfd50a2872b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ba27e485d5bb488bb0b3f61b5b95fb25":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"26335f9d5c144b459ecc68239bfa625a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"456f1489b02d465f80f231a13c8eaa17":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"90200e83d0924d1bacb603f4993cd2eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa9be888a1914c98ae4f111e233f30d9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}